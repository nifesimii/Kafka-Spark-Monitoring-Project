[2026-01-16 08:12:58,421] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2026-01-16 08:13:02,809] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2026-01-16 08:13:02,914] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:13:06,975] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:13:07,421] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:13:08,087] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-01-16 08:13:08,102] INFO [BrokerServer id=5] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2026-01-16 08:13:08,110] INFO [SharedServer id=5] Starting SharedServer (kafka.server.SharedServer)
[2026-01-16 08:13:08,146] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:13:09,102] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:13:09,150] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:13:09,156] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:13:09,494] INFO Initialized snapshots with IDs SortedSet() from /tmp/kafka-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2026-01-16 08:13:09,790] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-01-16 08:13:09,889] INFO [RaftManager id=5] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:13:09,907] INFO [RaftManager id=5] Starting request manager with static voters: [kafka-controller-1:9093 (id: 1 rack: null), kafka-controller-2:9093 (id: 2 rack: null), kafka-controller-3:9093 (id: 3 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:13:10,987] INFO [RaftManager id=5] Completed transition to Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1653) from null (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:13:10,999] INFO [kafka-5-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-01-16 08:13:11,002] INFO [kafka-5-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-01-16 08:13:11,378] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:11,418] INFO [BrokerServer id=5] Starting broker (kafka.server.BrokerServer)
[2026-01-16 08:13:11,480] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:11,493] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:13:11,582] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:11,685] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:11,787] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:11,790] INFO [broker-5-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:13:11,798] INFO [broker-5-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:13:11,807] INFO [broker-5-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:13:11,840] INFO [broker-5-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:13:11,892] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,027] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,136] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,237] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,344] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,458] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,560] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,667] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,739] INFO [BrokerServer id=5] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-01-16 08:13:12,741] INFO [BrokerServer id=5] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-01-16 08:13:12,772] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,795] INFO [broker-5-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:12,854] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-01-16 08:13:12,874] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:12,877] INFO [RaftManager id=5] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1748547887 (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:13:12,977] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,012] INFO [RaftManager id=5] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:13,078] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,104] WARN [RaftManager id=5] Connection to node 3 (kafka-controller-3/172.24.0.7:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:13,187] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,293] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,396] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,498] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,599] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,703] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,809] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:13,849] INFO [RaftManager id=5] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:13,855] WARN [RaftManager id=5] Connection to node 2 (kafka-controller-2/172.24.0.8:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:13,922] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,009] INFO [RaftManager id=5] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,013] WARN [RaftManager id=5] Connection to node 3 (kafka-controller-3/172.24.0.7:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,026] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,071] INFO [RaftManager id=5] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,076] WARN [RaftManager id=5] Connection to node 1 (kafka-controller-1/172.24.0.9:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,105] INFO [RaftManager id=5] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,125] WARN [RaftManager id=5] Connection to node 3 (kafka-controller-3/172.24.0.7:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,197] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,257] INFO [RaftManager id=5] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,287] WARN [RaftManager id=5] Connection to node 1 (kafka-controller-1/172.24.0.9:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,320] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,374] INFO [RaftManager id=5] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,405] WARN [RaftManager id=5] Connection to node 3 (kafka-controller-3/172.24.0.7:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,424] INFO [RaftManager id=5] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,426] WARN [RaftManager id=5] Connection to node 1 (kafka-controller-1/172.24.0.9:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,457] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,474] INFO [RaftManager id=5] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,478] WARN [RaftManager id=5] Connection to node 2 (kafka-controller-2/172.24.0.8:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,561] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,665] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,703] INFO [RaftManager id=5] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,705] WARN [RaftManager id=5] Connection to node 2 (kafka-controller-2/172.24.0.8:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,798] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,896] INFO [RaftManager id=5] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,899] WARN [RaftManager id=5] Connection to node 1 (kafka-controller-1/172.24.0.9:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,924] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:14,929] INFO [RaftManager id=5] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:14,953] WARN [RaftManager id=5] Connection to node 3 (kafka-controller-3/172.24.0.7:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:15,040] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,214] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,288] INFO [RaftManager id=5] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:16,319] WARN [RaftManager id=5] Connection to node 3 (kafka-controller-3/172.24.0.7:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:16,385] INFO [RaftManager id=5] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:16,423] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,437] WARN [RaftManager id=5] Connection to node 1 (kafka-controller-1/172.24.0.9:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:13:16,540] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,651] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,752] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,855] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:16,964] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,072] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,235] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,358] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,466] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,575] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,691] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,798] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:17,900] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,005] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,094] INFO [RaftManager id=5] Completed transition to Unattached(epoch=3, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=0, voters=[1, 2, 3], electionTimeoutMs=1653) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:13:18,112] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,230] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,372] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,418] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-01-16 08:13:18,476] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,632] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,735] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,819] INFO [SocketServer listenerType=BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2026-01-16 08:13:18,821] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-01-16 08:13:18,853] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:18,895] INFO [SocketServer listenerType=BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_HOST) (kafka.network.SocketServer)
[2026-01-16 08:13:18,967] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,022] INFO [broker-5-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:19,076] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,132] INFO [broker-5-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:19,179] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,278] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,281] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,328] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,389] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=3, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from Unattached(epoch=3, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:13:19,391] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,389] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,413] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,443] INFO [ExpirationReaper-5-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,491] INFO [broker-5-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:19,513] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:19,491] INFO [broker-5-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:19,515] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,642] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,745] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,750] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,762] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:19,856] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:19,971] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,109] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,227] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,330] INFO Unable to read the broker epoch in /tmp/kafka-logs. (kafka.log.LogManager)
[2026-01-16 08:13:20,347] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,368] INFO [BrokerLifecycleManager id=5] Incarnation DAF6_j_cQ16sRDOdFAu0-w of broker 5 in cluster 5L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:13:20,348] INFO [broker-5-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:20,412] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:13:20,447] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:13:20,469] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,499] INFO [RaftManager id=5] High watermark set to Optional[LogOffsetMetadata(offset=1, metadata=Optional.empty)] for the first time for epoch 3 (org.apache.kafka.raft.FollowerState)
[2026-01-16 08:13:20,582] INFO [MetadataLoader id=5] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,686] INFO [MetadataLoader id=5] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,706] INFO [MetadataLoader id=5] initializeNewPublishers: The loader finished catching up to the current high water mark of 1 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,770] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 0 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:20,800] INFO [BrokerLifecycleManager id=5] Successfully registered broker 5 with broker epoch 7 (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:13:21,027] INFO [BrokerServer id=5] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-01-16 08:13:21,054] INFO [BrokerServer id=5] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-01-16 08:13:21,055] INFO [BrokerServer id=5] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-01-16 08:13:21,039] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing MetadataVersionPublisher(id=5) with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:21,076] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:21,078] INFO [BrokerMetadataPublisher id=5] Publishing initial metadata at offset OffsetAndEpoch(offset=7, epoch=3) with metadata.version 3.8-IV0. (kafka.server.metadata.BrokerMetadataPublisher)
[2026-01-16 08:13:21,170] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:13:21,284] INFO [BrokerLifecycleManager id=5] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:13:21,286] INFO [BrokerServer id=5] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-01-16 08:13:21,286] INFO [BrokerServer id=5] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-01-16 08:13:21,420] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:13:21,441] INFO No logs found to be loaded in /tmp/kafka-logs (kafka.log.LogManager)
[2026-01-16 08:13:21,699] INFO Loaded 0 logs in 497ms (kafka.log.LogManager)
[2026-01-16 08:13:21,720] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2026-01-16 08:13:21,732] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2026-01-16 08:13:28,155] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2026-01-16 08:13:28,534] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:13:28,611] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-01-16 08:13:28,656] INFO [AddPartitionsToTxnSenderThread-5]: Starting (kafka.server.AddPartitionsToTxnManager)
[2026-01-16 08:13:28,672] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:13:29,022] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:13:29,040] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-01-16 08:13:29,153] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-01-16 08:13:29,154] INFO [TxnMarkerSenderThread-5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-01-16 08:13:29,871] INFO [BrokerServer id=5] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-01-16 08:13:29,894] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=5) with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:13:30,195] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://kafka-broker-2:19092,PLAINTEXT_HOST://localhost:39092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@kafka-controller-1:9093, 2@kafka-controller-2:9093, 3@kafka-controller-3:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
	listeners = PLAINTEXT://:19092,PLAINTEXT_HOST://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2026-01-16 08:13:30,286] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:13:30,328] INFO [BrokerServer id=5] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-01-16 08:13:30,931] INFO [BrokerLifecycleManager id=5] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:13:30,942] INFO [BrokerServer id=5] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-01-16 08:13:31,045] INFO authorizerStart completed for endpoint PLAINTEXT_HOST. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-01-16 08:13:31,059] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-01-16 08:13:31,140] INFO [SocketServer listenerType=BROKER, nodeId=5] Enabling request processing. (kafka.network.SocketServer)
[2026-01-16 08:13:31,301] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2026-01-16 08:13:31,444] INFO Awaiting socket connections on 0.0.0.0:19092. (kafka.network.DataPlaneAcceptor)
[2026-01-16 08:13:31,531] INFO [BrokerServer id=5] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-01-16 08:13:31,532] INFO [BrokerServer id=5] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-01-16 08:13:31,532] INFO [BrokerServer id=5] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-01-16 08:13:31,532] INFO [BrokerServer id=5] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-01-16 08:13:31,533] INFO [BrokerServer id=5] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2026-01-16 08:13:31,551] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[2026-01-16 08:13:31,552] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser)
[2026-01-16 08:13:31,561] INFO Kafka startTimeMs: 1768551211542 (org.apache.kafka.common.utils.AppInfoParser)
[2026-01-16 08:13:31,610] INFO [KafkaRaftServer nodeId=5] Kafka Server started (kafka.server.KafkaRaftServer)
[2026-01-16 08:14:38,332] INFO [RaftManager id=5] Completed transition to Unattached(epoch=4, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=3, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=158, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:14:38,400] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:14:38,733] INFO [RaftManager id=5] Completed transition to Unattached(epoch=7, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=4, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:14:39,263] INFO [RaftManager id=5] Completed transition to Unattached(epoch=8, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=7, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:14:39,799] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=8, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=158, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=8, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:14:39,880] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:14:45,636] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(_schemas-0) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:14:47,324] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:14:47,562] INFO Created log for partition _schemas-0 in /tmp/kafka-logs/_schemas-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2026-01-16 08:14:47,638] INFO [Partition _schemas-0 broker=5] No checkpointed highwatermark is found for partition _schemas-0 (kafka.cluster.Partition)
[2026-01-16 08:14:47,684] INFO [Partition _schemas-0 broker=5] Log loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:14:48,181] INFO [DynamicConfigPublisher broker id=5] Updating topic _schemas with new configuration : cleanup.policy -> compact (kafka.server.metadata.DynamicConfigPublisher)
[2026-01-16 08:15:02,706] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-01-16 08:15:05,336] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2026-01-16 08:15:05,481] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-13, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-41, __consumer_offsets-22, __consumer_offsets-49, __consumer_offsets-18, __consumer_offsets-0, __consumer_offsets-32, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-6, __consumer_offsets-4, __consumer_offsets-36, __consumer_offsets-34) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:15:06,128] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:06,154] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:06,161] INFO [Partition __consumer_offsets-47 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2026-01-16 08:15:06,162] INFO [Partition __consumer_offsets-47 broker=5] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:06,293] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:06,299] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:06,300] INFO [Partition __consumer_offsets-16 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2026-01-16 08:15:06,300] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:06,394] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:06,417] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:06,418] INFO [Partition __consumer_offsets-13 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2026-01-16 08:15:06,422] INFO [Partition __consumer_offsets-13 broker=5] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:06,660] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:06,706] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:06,719] INFO [Partition __consumer_offsets-11 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2026-01-16 08:15:06,722] INFO [Partition __consumer_offsets-11 broker=5] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:06,888] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:07,016] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:07,033] INFO [Partition __consumer_offsets-44 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2026-01-16 08:15:07,045] INFO [Partition __consumer_offsets-44 broker=5] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:07,103] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:07,108] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:07,110] INFO [Partition __consumer_offsets-41 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2026-01-16 08:15:07,113] INFO [Partition __consumer_offsets-41 broker=5] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:07,150] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:07,156] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:07,158] INFO [Partition __consumer_offsets-22 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2026-01-16 08:15:07,158] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:07,208] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:07,232] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:07,239] INFO [Partition __consumer_offsets-49 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2026-01-16 08:15:07,241] INFO [Partition __consumer_offsets-49 broker=5] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:07,364] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:07,444] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:07,455] INFO [Partition __consumer_offsets-18 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2026-01-16 08:15:07,768] INFO [Partition __consumer_offsets-18 broker=5] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,143] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,199] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,221] INFO [Partition __consumer_offsets-0 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,236] INFO [Partition __consumer_offsets-0 broker=5] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,315] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,328] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,331] INFO [Partition __consumer_offsets-32 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2026-01-16 08:15:08,332] INFO [Partition __consumer_offsets-32 broker=5] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,366] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,370] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,370] INFO [Partition __consumer_offsets-27 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2026-01-16 08:15:08,371] INFO [Partition __consumer_offsets-27 broker=5] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,573] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,583] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,588] INFO [Partition __consumer_offsets-25 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2026-01-16 08:15:08,589] INFO [Partition __consumer_offsets-25 broker=5] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,684] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,688] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,696] INFO [Partition __consumer_offsets-6 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2026-01-16 08:15:08,702] INFO [Partition __consumer_offsets-6 broker=5] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,789] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,806] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,809] INFO [Partition __consumer_offsets-4 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2026-01-16 08:15:08,810] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:08,862] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:08,868] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:08,871] INFO [Partition __consumer_offsets-36 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2026-01-16 08:15:08,871] INFO [Partition __consumer_offsets-36 broker=5] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:09,034] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:09,086] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:09,095] INFO [Partition __consumer_offsets-34 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2026-01-16 08:15:09,097] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:09,606] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:09,614] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:09,615] INFO [Partition __consumer_offsets-15 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2026-01-16 08:15:09,616] INFO [Partition __consumer_offsets-15 broker=5] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:09,730] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:09,735] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:09,736] INFO [Partition __consumer_offsets-48 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2026-01-16 08:15:09,736] INFO [Partition __consumer_offsets-48 broker=5] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:09,852] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:09,864] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:09,869] INFO [Partition __consumer_offsets-46 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2026-01-16 08:15:09,871] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:09,916] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:09,939] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:09,947] INFO [Partition __consumer_offsets-9 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2026-01-16 08:15:09,950] INFO [Partition __consumer_offsets-9 broker=5] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:09,982] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:09,987] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:09,988] INFO [Partition __consumer_offsets-42 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2026-01-16 08:15:09,988] INFO [Partition __consumer_offsets-42 broker=5] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:10,025] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:10,033] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:10,037] INFO [Partition __consumer_offsets-23 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2026-01-16 08:15:10,049] INFO [Partition __consumer_offsets-23 broker=5] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:10,117] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:10,156] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:10,186] INFO [Partition __consumer_offsets-21 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2026-01-16 08:15:10,190] INFO [Partition __consumer_offsets-21 broker=5] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:10,300] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:10,312] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:10,312] INFO [Partition __consumer_offsets-19 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2026-01-16 08:15:10,313] INFO [Partition __consumer_offsets-19 broker=5] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:10,730] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:10,776] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:10,777] INFO [Partition __consumer_offsets-17 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2026-01-16 08:15:10,778] INFO [Partition __consumer_offsets-17 broker=5] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:10,818] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:10,829] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:10,845] INFO [Partition __consumer_offsets-30 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2026-01-16 08:15:10,853] INFO [Partition __consumer_offsets-30 broker=5] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,111] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,113] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,118] INFO [Partition __consumer_offsets-28 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2026-01-16 08:15:11,118] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,174] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,177] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,180] INFO [Partition __consumer_offsets-26 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2026-01-16 08:15:11,188] INFO [Partition __consumer_offsets-26 broker=5] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,207] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,210] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,211] INFO [Partition __consumer_offsets-7 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2026-01-16 08:15:11,213] INFO [Partition __consumer_offsets-7 broker=5] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,247] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,260] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,262] INFO [Partition __consumer_offsets-40 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2026-01-16 08:15:11,263] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,304] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,312] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,322] INFO [Partition __consumer_offsets-5 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2026-01-16 08:15:11,322] INFO [Partition __consumer_offsets-5 broker=5] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,397] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,450] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,453] INFO [Partition __consumer_offsets-38 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2026-01-16 08:15:11,453] INFO [Partition __consumer_offsets-38 broker=5] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,471] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,474] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,485] INFO [Partition __consumer_offsets-3 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2026-01-16 08:15:11,487] INFO [Partition __consumer_offsets-3 broker=5] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,700] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,718] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,735] INFO [Partition __consumer_offsets-1 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2026-01-16 08:15:11,740] INFO [Partition __consumer_offsets-1 broker=5] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,869] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,884] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,913] INFO [Partition __consumer_offsets-45 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2026-01-16 08:15:11,915] INFO [Partition __consumer_offsets-45 broker=5] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:11,956] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:11,966] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:11,968] INFO [Partition __consumer_offsets-14 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2026-01-16 08:15:11,969] INFO [Partition __consumer_offsets-14 broker=5] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,200] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,235] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,236] INFO [Partition __consumer_offsets-43 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2026-01-16 08:15:12,236] INFO [Partition __consumer_offsets-43 broker=5] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,473] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,531] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,534] INFO [Partition __consumer_offsets-12 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2026-01-16 08:15:12,545] INFO [Partition __consumer_offsets-12 broker=5] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,695] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,702] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,703] INFO [Partition __consumer_offsets-10 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2026-01-16 08:15:12,707] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,761] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,762] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,763] INFO [Partition __consumer_offsets-24 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2026-01-16 08:15:12,764] INFO [Partition __consumer_offsets-24 broker=5] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,804] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,847] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,854] INFO [Partition __consumer_offsets-20 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2026-01-16 08:15:12,854] INFO [Partition __consumer_offsets-20 broker=5] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,900] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,903] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,903] INFO [Partition __consumer_offsets-31 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2026-01-16 08:15:12,904] INFO [Partition __consumer_offsets-31 broker=5] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,942] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,952] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:12,953] INFO [Partition __consumer_offsets-29 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2026-01-16 08:15:12,953] INFO [Partition __consumer_offsets-29 broker=5] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:12,985] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:12,998] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:13,000] INFO [Partition __consumer_offsets-39 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2026-01-16 08:15:13,002] INFO [Partition __consumer_offsets-39 broker=5] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:13,034] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:13,041] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:13,046] INFO [Partition __consumer_offsets-8 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2026-01-16 08:15:13,048] INFO [Partition __consumer_offsets-8 broker=5] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:13,075] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:13,082] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:13,084] INFO [Partition __consumer_offsets-37 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2026-01-16 08:15:13,084] INFO [Partition __consumer_offsets-37 broker=5] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:13,117] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:13,122] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:13,124] INFO [Partition __consumer_offsets-35 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2026-01-16 08:15:13,125] INFO [Partition __consumer_offsets-35 broker=5] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:13,284] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:13,298] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:13,308] INFO [Partition __consumer_offsets-33 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2026-01-16 08:15:13,315] INFO [Partition __consumer_offsets-33 broker=5] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:13,419] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:15:13,447] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2026-01-16 08:15:13,460] INFO [Partition __consumer_offsets-2 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2026-01-16 08:15:13,473] INFO [Partition __consumer_offsets-2 broker=5] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:15:13,498] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-23, __consumer_offsets-21, __consumer_offsets-19, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-28, __consumer_offsets-26, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-3, __consumer_offsets-1, __consumer_offsets-45, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-12, __consumer_offsets-10, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-31, __consumer_offsets-29, __consumer_offsets-39, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-35, __consumer_offsets-33, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:15:14,333] INFO [ReplicaFetcherThread-0-4]: Starting (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,346] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-15 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,350] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions HashMap(__consumer_offsets-15 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-48 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-14 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-46 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-42 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-10 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-23 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-24 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-19 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-29 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-30 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-7 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-40 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-5 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-38 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-33 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0), __consumer_offsets-2 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),0,0)) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:15:14,376] INFO [UnifiedLog partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,395] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-48 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,401] INFO [UnifiedLog partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,402] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-14 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,405] INFO [UnifiedLog partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,408] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-46 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,412] INFO [UnifiedLog partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,426] INFO [ReplicaFetcherThread-0-6]: Starting (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,427] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-45 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,430] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 6 for partitions HashMap(__consumer_offsets-45 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-43 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-12 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-9 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-21 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-20 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-17 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-31 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-28 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-26 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-39 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-8 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-37 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-35 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-3 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0), __consumer_offsets-1 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),0,0)) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:15:14,429] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-42 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,435] INFO [UnifiedLog partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,441] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,443] INFO [UnifiedLog partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,448] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-23 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,431] INFO [UnifiedLog partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,453] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-43 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,454] INFO [UnifiedLog partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,450] INFO [UnifiedLog partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,462] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-24 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,462] INFO [UnifiedLog partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,460] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-12 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,464] INFO [UnifiedLog partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,467] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,463] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-19 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,472] INFO [UnifiedLog partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,472] INFO [UnifiedLog partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,476] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-21 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,479] INFO [UnifiedLog partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,474] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,484] INFO [UnifiedLog partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,486] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-30 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,484] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-20 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,491] INFO [UnifiedLog partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,493] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,491] INFO [UnifiedLog partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,496] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,496] INFO [UnifiedLog partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,499] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-40 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,501] INFO [UnifiedLog partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,504] INFO [UnifiedLog partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,507] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,510] INFO [UnifiedLog partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,510] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-31 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,512] INFO [UnifiedLog partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,515] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,515] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-38 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,515] INFO [UnifiedLog partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,516] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-33 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,515] INFO [UnifiedLog partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,520] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,520] INFO [UnifiedLog partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,522] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,522] INFO [UnifiedLog partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,523] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-39 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,524] INFO [UnifiedLog partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,523] INFO [UnifiedLog partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,532] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,540] INFO [UnifiedLog partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,543] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,544] INFO [UnifiedLog partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,555] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,555] INFO [UnifiedLog partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,555] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,555] INFO [UnifiedLog partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,555] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:15:14,555] INFO [UnifiedLog partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:15:14,934] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:14,980] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:14,985] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:14,991] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:14,999] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,001] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,003] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,005] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,007] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,011] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,013] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,014] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,014] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,015] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,015] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,020] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,021] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,021] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,021] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,021] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,022] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,023] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,023] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,024] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,024] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,027] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,027] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,028] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,030] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,030] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,030] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,035] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,044] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,061] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,083] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,086] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,106] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,120] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,128] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,104] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-47 in 100 milliseconds for epoch 0, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,133] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 134 milliseconds for epoch 0, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,129] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,137] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,139] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,142] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,147] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 21 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,151] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,159] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,163] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,142] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-13 in 139 milliseconds for epoch 0, of which 131 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,170] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-11 in 163 milliseconds for epoch 0, of which 163 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,164] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,175] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-44 in 162 milliseconds for epoch 0, of which 161 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,179] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,187] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,189] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,190] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,191] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,194] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,192] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-41 in 178 milliseconds for epoch 0, of which 167 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,195] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,204] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,198] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 183 milliseconds for epoch 0, of which 183 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,205] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-49 in 189 milliseconds for epoch 0, of which 189 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,205] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,208] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,213] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,217] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,213] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-18 in 193 milliseconds for epoch 0, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,225] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-0 in 204 milliseconds for epoch 0, of which 204 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,222] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,226] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,228] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,229] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,233] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-32 in 212 milliseconds for epoch 0, of which 205 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,235] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-27 in 212 milliseconds for epoch 0, of which 212 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,234] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,236] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,240] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,238] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-25 in 214 milliseconds for epoch 0, of which 214 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,246] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,248] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,249] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-6 in 223 milliseconds for epoch 0, of which 221 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,256] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,259] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,264] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,262] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 234 milliseconds for epoch 0, of which 228 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,264] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,266] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,265] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-36 in 235 milliseconds for epoch 0, of which 234 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,268] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 235 milliseconds for epoch 0, of which 234 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,267] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,276] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,277] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,279] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,279] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,280] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,280] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,280] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,280] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,280] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,280] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,280] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,280] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,281] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,282] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,283] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,284] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,283] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,284] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,285] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,289] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,286] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,290] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,290] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:15:15,293] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,290] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,300] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,311] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,314] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,312] INFO [DynamicConfigPublisher broker id=5] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2026-01-16 08:15:15,318] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-21 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,325] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,327] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,331] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,335] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,340] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,341] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,346] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,353] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,355] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,357] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,364] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,367] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,373] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,378] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,386] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,388] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,390] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,390] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,391] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,392] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,398] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,398] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,398] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,400] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,401] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:15,403] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:15:53,598] INFO [RaftManager id=5] Completed transition to Unattached(epoch=9, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=8, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=353, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:15:53,713] INFO [RaftManager id=5] Completed transition to Unattached(epoch=10, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=9, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:15:55,090] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:15:55,173] INFO [RaftManager id=5] Completed transition to Unattached(epoch=11, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=10, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:15:55,320] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=12, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=353, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=11, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:15:55,370] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:19:00,884] INFO [RaftManager id=5] Completed transition to Unattached(epoch=13, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=12, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=715, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:01,246] INFO [RaftManager id=5] Completed transition to Unattached(epoch=14, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=13, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:01,408] INFO [RaftManager id=5] Completed transition to Unattached(epoch=15, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=14, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:01,846] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:01,991] INFO [RaftManager id=5] Completed transition to Unattached(epoch=16, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=15, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:02,081] INFO [RaftManager id=5] Completed transition to Unattached(epoch=17, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=16, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:02,491] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=18, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=715, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=17, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:02,503] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:19:38,863] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:39,261] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 807 due to node 1 being disconnected (elapsed time since creation: 2029ms, elapsed time since send: 2029ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:43,147] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:43,642] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 177 due to node 1 being disconnected (elapsed time since creation: 5504ms, elapsed time since send: 5478ms, throttle time: 0ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:43,877] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:19:44,939] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:19:45,542] INFO [RaftManager id=5] Completed transition to Unattached(epoch=21, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=18, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:46,612] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:48,406] INFO [RaftManager id=5] Completed transition to Unattached(epoch=22, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=21, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:49,374] INFO [RaftManager id=5] Completed transition to Unattached(epoch=24, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=22, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:49,858] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:19:51,804] INFO [RaftManager id=5] Completed transition to Unattached(epoch=25, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=24, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:52,808] INFO [RaftManager id=5] Completed transition to Unattached(epoch=26, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=25, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:54,803] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:19:55,630] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:56,033] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 817 due to node 3 being disconnected (elapsed time since creation: 2082ms, elapsed time since send: 2009ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:19:57,044] INFO [RaftManager id=5] Completed transition to Unattached(epoch=27, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=26, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:19:57,119] INFO [RaftManager id=5] Completed transition to Unattached(epoch=28, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=27, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:20:00,852] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:20:02,420] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:03,250] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 820 due to node 3 being disconnected (elapsed time since creation: 2991ms, elapsed time since send: 2004ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:06,815] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:06,946] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 822 due to node 2 being disconnected (elapsed time since creation: 7437ms, elapsed time since send: 3260ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:07,538] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:20:08,145] INFO [RaftManager id=5] Completed transition to Unattached(epoch=30, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=28, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:20:08,483] INFO [RaftManager id=5] Completed transition to Unattached(epoch=32, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=30, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:20:17,857] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:20:18,703] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:18,833] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 829 due to node 2 being disconnected (elapsed time since creation: 8663ms, elapsed time since send: 8663ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:23,114] INFO [RaftManager id=5] Completed transition to Unattached(epoch=37, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=32, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:20:24,686] INFO [RaftManager id=5] Completed transition to Unattached(epoch=39, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=37, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:20:36,902] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:20:49,155] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:20:51,659] INFO [RaftManager id=5] Completed transition to Unattached(epoch=48, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=39, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:20:59,076] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:20:59,529] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 841 due to node 1 being disconnected (elapsed time since creation: 4946ms, elapsed time since send: 4166ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:04,213] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:21:05,286] INFO [RaftManager id=5] Completed transition to Unattached(epoch=54, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=48, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:21:10,571] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:10,929] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 845 due to node 1 being disconnected (elapsed time since creation: 2734ms, elapsed time since send: 2133ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:11,765] INFO [RaftManager id=5] Completed transition to Unattached(epoch=57, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=54, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:21:16,251] INFO [RaftManager id=5] Completed transition to Unattached(epoch=58, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=57, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:21:18,013] INFO [RaftManager id=5] Completed transition to Unattached(epoch=59, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=58, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:21:21,327] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:21:23,917] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:25,227] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 849 due to node 3 being disconnected (elapsed time since creation: 4213ms, elapsed time since send: 2002ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:29,175] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:29,895] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 851 due to node 1 being disconnected (elapsed time since creation: 2295ms, elapsed time since send: 2295ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:35,693] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:21:43,380] INFO [RaftManager id=5] Completed transition to Unattached(epoch=70, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=59, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:21:45,906] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:46,185] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 860 due to node 3 being disconnected (elapsed time since creation: 2119ms, elapsed time since send: 2104ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:51,232] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:51,300] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 862 due to node 3 being disconnected (elapsed time since creation: 4437ms, elapsed time since send: 4437ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:21:56,298] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:21:56,771] INFO [RaftManager id=5] Completed transition to Unattached(epoch=77, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=70, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:21:57,715] INFO [RaftManager id=5] Completed transition to Unattached(epoch=78, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=77, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:00,851] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:01,383] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 871 due to node 3 being disconnected (elapsed time since creation: 2131ms, elapsed time since send: 2131ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:07,401] INFO [RaftManager id=5] Completed transition to Unattached(epoch=81, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=78, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:09,458] INFO [RaftManager id=5] Completed transition to Unattached(epoch=82, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=81, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:10,465] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:22:10,501] INFO [RaftManager id=5] Completed transition to Unattached(epoch=85, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=82, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:18,268] INFO [RaftManager id=5] Completed transition to Unattached(epoch=88, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=85, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:23,170] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:23,527] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 882 due to node 1 being disconnected (elapsed time since creation: 2535ms, elapsed time since send: 2150ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:25,607] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:22:26,877] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:27,275] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 883 due to node 2 being disconnected (elapsed time since creation: 4184ms, elapsed time since send: 2414ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:32,540] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:33,073] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 887 due to node 2 being disconnected (elapsed time since creation: 2018ms, elapsed time since send: 2018ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:33,094] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:33,118] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 884 due to node 3 being disconnected (elapsed time since creation: 7202ms, elapsed time since send: 3826ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:22:42,640] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:22:44,264] INFO [RaftManager id=5] Completed transition to Unattached(epoch=95, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=88, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:47,693] INFO [RaftManager id=5] Completed transition to Unattached(epoch=97, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=95, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:51,694] INFO [RaftManager id=5] Completed transition to Unattached(epoch=99, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=97, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:56,829] INFO [RaftManager id=5] Completed transition to Unattached(epoch=101, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=99, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:22:57,432] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:22:57,926] INFO [RaftManager id=5] Completed transition to Unattached(epoch=103, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=101, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:04,197] INFO [RaftManager id=5] Completed transition to Unattached(epoch=107, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=103, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:06,657] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:23:06,837] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 904 due to node 1 being disconnected (elapsed time since creation: 2165ms, elapsed time since send: 2164ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:23:08,822] INFO [RaftManager id=5] Completed transition to Unattached(epoch=110, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=107, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:09,324] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=110, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=110, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:09,864] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:23:16,302] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:23:16,333] INFO [RaftManager id=5] Completed transition to Unattached(epoch=111, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=110, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:17,085] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:23:17,097] INFO [RaftManager id=5] Completed transition to Unattached(epoch=113, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=111, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:26,362] INFO [RaftManager id=5] Completed transition to Unattached(epoch=114, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=113, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:29,040] INFO [RaftManager id=5] Completed transition to Unattached(epoch=119, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=114, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:29,365] INFO [RaftManager id=5] Completed transition to Unattached(epoch=121, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=119, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:31,517] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:23:31,981] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=121, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=121, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:32,029] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:23:39,031] INFO [RaftManager id=5] Completed transition to Unattached(epoch=122, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=121, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:44,305] INFO [RaftManager id=5] Completed transition to Unattached(epoch=127, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=122, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:44,709] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=128, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=127, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:23:45,525] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:23:45,982] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:23:45,987] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:24:02,463] INFO [RaftManager id=5] Completed transition to Unattached(epoch=132, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=128, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:24:05,761] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:06,657] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:24:06,659] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 925 due to node 3 being disconnected (elapsed time since creation: 2480ms, elapsed time since send: 2135ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:10,465] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:11,367] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=136, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=132, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:24:17,815] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:18,226] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:19,557] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:19,644] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:19,810] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:19,964] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:19,967] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:20,017] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:20,076] INFO [RaftManager id=5] Completed transition to Unattached(epoch=140, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=136, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:24:20,160] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=141, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=140, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:24:20,181] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:20,199] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:23,068] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:23,497] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:23,499] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:24:29,721] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Truncating to offset 788 (kafka.log.UnifiedLog)
[2026-01-16 08:24:38,257] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 788 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:24:38,334] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 788 (kafka.log.UnifiedLog$)
[2026-01-16 08:24:38,656] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 788 with 0 producer ids in 75 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:24:39,370] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 1034ms for segment recovery from offset 788 (kafka.log.UnifiedLog$)
[2026-01-16 08:24:39,421] INFO [RaftManager id=5] Truncated to offset 788 from Fetch response from leader 3 (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:24:41,975] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=147, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=141, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=780, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:24:50,004] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:50,512] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 938 due to node 3 being disconnected (elapsed time since creation: 2051ms, elapsed time since send: 2009ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:50,660] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:50,716] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:56,304] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:56,538] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:56,660] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:24:56,813] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 940 due to node 3 being disconnected (elapsed time since creation: 2924ms, elapsed time since send: 2924ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:57,883] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:57,937] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:58,090] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:58,421] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:58,455] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:58,797] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:58,873] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:58,979] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:59,313] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:59,318] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:59,376] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:24:59,609] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:24:59,624] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:00,597] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:00,638] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:01,204] INFO [RaftManager id=5] Completed transition to Unattached(epoch=155, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=147, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:01,315] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:01,827] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:02,143] INFO [RaftManager id=5] Completed transition to Unattached(epoch=158, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=155, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:02,962] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=158, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=158, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:03,018] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:08,119] INFO [NodeToControllerChannelManager id=5 name=forwarding] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:08,504] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:08,699] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:09,954] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:10,118] INFO [RaftManager id=5] Completed transition to Unattached(epoch=161, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=158, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:10,336] INFO [RaftManager id=5] Completed transition to Unattached(epoch=162, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=161, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:14,014] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:14,393] INFO [RaftManager id=5] Completed transition to Unattached(epoch=165, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=162, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:17,038] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:17,282] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=166, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=165, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:23,650] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:24,266] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:24,270] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:24,356] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 962 due to node 2 being disconnected (elapsed time since creation: 5737ms, elapsed time since send: 5736ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:25,378] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=170, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=166, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:25,442] INFO [RaftManager id=5] Completed transition to Unattached(epoch=171, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=170, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:28,463] INFO [RaftManager id=5] Completed transition to Unattached(epoch=172, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=171, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:28,943] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:31,351] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:32,103] INFO [RaftManager id=5] Completed transition to Unattached(epoch=174, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=172, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:34,854] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=174, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=807, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=174, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:34,934] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:39,490] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:39,691] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:39,696] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:41,557] INFO [RaftManager id=5] Completed transition to Unattached(epoch=178, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=174, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=871, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:42,001] INFO [RaftManager id=5] Completed transition to Unattached(epoch=179, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=178, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:42,430] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=179, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=871, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=179, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:48,607] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-21, __consumer_offsets-32, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-34, __consumer_offsets-47, _schemas-0, __consumer_offsets-16, __consumer_offsets-43, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-22, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-6, __consumer_offsets-4) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:25:53,460] INFO [RaftManager id=5] Completed transition to Unattached(epoch=180, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=179, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=893, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:53,869] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:54,254] INFO [RaftManager id=5] Completed transition to Unattached(epoch=183, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=180, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:54,490] INFO [RaftManager id=5] Completed transition to Unattached(epoch=185, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=183, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:54,967] INFO [RaftManager id=5] Completed transition to Unattached(epoch=186, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=185, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:55,028] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-45 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,174] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-45 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,240] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-9 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,277] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-9 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,307] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-17 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,359] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-17 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,369] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-28 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,667] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-28 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,672] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-26 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,676] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-26 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,750] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-39 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,789] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-39 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,790] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-37 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,790] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-37 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,795] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-35 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,803] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-35 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,807] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-1 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:55,809] WARN [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Partition __consumer_offsets-1 marked as failed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:25:56,199] INFO [RaftManager id=5] Completed transition to Unattached(epoch=187, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=186, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:56,545] INFO [RaftManager id=5] Completed transition to Unattached(epoch=188, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=187, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:58,413] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:25:58,653] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=188, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=893, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=188, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:58,686] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:58,686] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-45, __consumer_offsets-28, __consumer_offsets-9, __consumer_offsets-26, __consumer_offsets-39, __consumer_offsets-37, __consumer_offsets-35, __consumer_offsets-17, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:25:59,061] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:25:59,122] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=189, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=893, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=188, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=893, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:25:59,226] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:25:59,284] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Truncating to offset 897 (kafka.log.UnifiedLog)
[2026-01-16 08:26:00,826] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions HashMap(__consumer_offsets-45 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-28 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-9 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-26 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-39 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-37 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-35 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-17 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0), __consumer_offsets-1 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=4, host=kafka-broker-1:19092),1,0)) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:26:01,616] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 897 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:26:01,633] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 897 (kafka.log.UnifiedLog$)
[2026-01-16 08:26:01,781] INFO [ProducerStateManager partition=__cluster_metadata-0] Loading producer state from snapshot file 'SnapshotFile(offset=788, file=/tmp/kafka-logs/__cluster_metadata-0/00000000000000000788.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:26:02,384] INFO [ReplicaFetcherThread-0-6]: Shutting down (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:03,109] INFO [ReplicaFetcherThread-0-6]: Stopped (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:03,236] INFO [ReplicaFetcherThread-0-6]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:03,694] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 897 with 0 producer ids in 44 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:26:03,732] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 1699ms for snapshot load and 394ms for segment recovery from offset 897 (kafka.log.UnifiedLog$)
[2026-01-16 08:26:03,733] INFO [RaftManager id=5] Truncated to offset 897 from Fetch response from leader 3 (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:26:03,871] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-45 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,486] INFO [UnifiedLog partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,597] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,614] INFO [UnifiedLog partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,631] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,676] INFO [UnifiedLog partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,693] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,700] INFO [UnifiedLog partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,717] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-39 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,719] INFO [UnifiedLog partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,759] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,772] INFO [UnifiedLog partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,806] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,829] INFO [UnifiedLog partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,884] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,900] INFO [UnifiedLog partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:04,955] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition __consumer_offsets-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:26:04,961] INFO [UnifiedLog partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:26:06,240] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:26:06,254] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:26:06,864] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 31 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:06,922] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:06,930] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 43 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:06,943] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:06,955] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 12 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:06,986] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:06,987] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 8 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:06,999] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,000] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 21 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,001] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,002] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 3 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,006] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,010] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 20 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,015] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,025] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,060] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,119] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,119] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,119] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,119] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,120] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,120] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,120] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,120] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,120] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,121] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,121] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,122] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,124] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,124] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,125] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,134] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,135] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,136] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,145] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,145] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,155] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,164] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,169] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,141] INFO [Partition __consumer_offsets-47 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:07,174] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,188] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,188] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,155] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-31 in 226 milliseconds for epoch 1, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,193] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,203] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,203] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,206] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,206] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-43 in 248 milliseconds for epoch 1, of which 240 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,213] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,219] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,219] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,219] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-12 in 232 milliseconds for epoch 1, of which 232 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,222] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-8 in 222 milliseconds for epoch 1, of which 222 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,222] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,222] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,222] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,222] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,222] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,222] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-21 in 220 milliseconds for epoch 1, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,225] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-3 in 216 milliseconds for epoch 1, of which 215 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,229] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,240] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,248] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,232] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-20 in 214 milliseconds for epoch 1, of which 207 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,250] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,249] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,253] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,256] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,272] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,276] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,274] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,280] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,281] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,285] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,285] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,292] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,289] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,295] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,297] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:07,297] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,299] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,299] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,300] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,315] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,317] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,321] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,323] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,327] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,329] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,349] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,365] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,376] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,386] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:07,406] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:08,301] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:08,317] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:08,355] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:08,359] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:08,368] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:08,357] INFO [Partition __consumer_offsets-13 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,379] INFO [Partition __consumer_offsets-11 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,417] INFO [Partition __consumer_offsets-44 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,418] INFO [Partition __consumer_offsets-21 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,452] INFO [Partition __consumer_offsets-32 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,456] INFO [Partition __consumer_offsets-3 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,458] INFO [Partition __consumer_offsets-36 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,459] INFO [Partition __consumer_offsets-34 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,460] INFO [Partition __consumer_offsets-16 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,460] INFO [Partition _schemas-0 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,463] INFO [Partition __consumer_offsets-43 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,468] INFO [Partition __consumer_offsets-12 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,469] INFO [Partition __consumer_offsets-41 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,470] INFO [Partition __consumer_offsets-22 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,478] INFO [Partition __consumer_offsets-20 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,484] INFO [Partition __consumer_offsets-49 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,485] INFO [Partition __consumer_offsets-18 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,485] INFO [Partition __consumer_offsets-31 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,485] INFO [Partition __consumer_offsets-0 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,486] INFO [Partition __consumer_offsets-27 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,494] INFO [Partition __consumer_offsets-25 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,496] INFO [Partition __consumer_offsets-8 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,498] INFO [Partition __consumer_offsets-6 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,498] INFO [Partition __consumer_offsets-4 broker=5] ISR updated to 5,4,6  and version updated to 2 (kafka.cluster.Partition)
[2026-01-16 08:26:08,588] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-47) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:26:09,529] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,536] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,556] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,556] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,556] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,557] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,557] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,557] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,558] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,569] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,572] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,574] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,557] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,576] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,578] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,589] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,589] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,591] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,576] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,595] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,596] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,598] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,599] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,596] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,601] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,600] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,611] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,611] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,613] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,613] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,614] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,615] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,619] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,622] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,629] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,630] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,630] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,630] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,630] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,630] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,630] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,630] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,630] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,631] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,614] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,633] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,640] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,648] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,648] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,635] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,650] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,651] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,653] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,654] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,658] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,658] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,659] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,659] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,650] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,662] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,662] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,662] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,663] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,663] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,662] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,664] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,664] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,664] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,666] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,676] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,676] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:09,677] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,892] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,910] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,910] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,910] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,910] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,911] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:09,935] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-21, __consumer_offsets-32, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-34, __consumer_offsets-47, _schemas-0, __consumer_offsets-16, __consumer_offsets-43, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-22, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-6, __consumer_offsets-4) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:26:10,389] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,394] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,396] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,399] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,399] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,400] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,400] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,400] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,405] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,403] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,410] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,413] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,414] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,413] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,418] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,422] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,420] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,424] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,427] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,426] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,436] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,436] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,437] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,437] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,437] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,438] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,438] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,439] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,439] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,440] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,440] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,441] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,443] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,445] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,448] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,451] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,453] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,453] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,455] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,455] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,459] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,460] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:10,845] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,909] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,910] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,910] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,911] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,919] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,922] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,943] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,967] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,967] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,898] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:10,983] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,016] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,029] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,034] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,039] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,040] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,040] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,043] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,054] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,055] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,057] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,058] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,074] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,054] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,084] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,080] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,139] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,139] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:11,139] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,151] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,151] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,175] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,204] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,205] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,261] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:11,360] INFO [Partition __consumer_offsets-47 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,566] INFO [Partition __consumer_offsets-13 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,578] INFO [Partition __consumer_offsets-11 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,578] INFO [Partition __consumer_offsets-44 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,583] INFO [Partition __consumer_offsets-21 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,599] INFO [Partition __consumer_offsets-32 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,603] INFO [Partition __consumer_offsets-3 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,605] INFO [Partition __consumer_offsets-36 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,615] INFO [Partition __consumer_offsets-34 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,616] INFO [Partition __consumer_offsets-16 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,617] INFO [Partition _schemas-0 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,623] INFO [Partition __consumer_offsets-43 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,625] INFO [Partition __consumer_offsets-12 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,627] INFO [Partition __consumer_offsets-41 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,639] INFO [Partition __consumer_offsets-22 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,650] INFO [Partition __consumer_offsets-20 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,656] INFO [Partition __consumer_offsets-49 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,660] INFO [Partition __consumer_offsets-18 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,667] INFO [Partition __consumer_offsets-31 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,686] INFO [Partition __consumer_offsets-0 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,690] INFO [Partition __consumer_offsets-27 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,701] INFO [Partition __consumer_offsets-25 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,711] INFO [Partition __consumer_offsets-8 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,713] INFO [Partition __consumer_offsets-6 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:11,741] INFO [Partition __consumer_offsets-4 broker=5] ISR updated to 5,4,6  and version updated to 4 (kafka.cluster.Partition)
[2026-01-16 08:26:12,294] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-21, __consumer_offsets-32, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-34, __consumer_offsets-47, _schemas-0, __consumer_offsets-16, __consumer_offsets-43, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-22, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-6, __consumer_offsets-4) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:26:14,916] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,030] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,126] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,411] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,412] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,413] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,416] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,420] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,414] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,421] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,421] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,421] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,422] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,422] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,422] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,422] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,422] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,422] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,422] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,423] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,423] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,424] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,425] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,425] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,425] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,425] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,425] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,425] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,425] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,423] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,426] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,426] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,429] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,430] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,429] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,431] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,431] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,430] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,433] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,433] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,432] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,436] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,437] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,436] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,441] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,441] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,441] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,442] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,442] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,442] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,443] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,443] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,443] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,444] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,444] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,445] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,445] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,444] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,446] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,447] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,446] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,450] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,452] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,453] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,458] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,458] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,452] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,459] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,459] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,459] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,460] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,462] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,834] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,880] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,898] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,945] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:26:15,946] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:26:15,966] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:28:04,169] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:28:04,603] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1266 due to node 3 being disconnected (elapsed time since creation: 2021ms, elapsed time since send: 2010ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:28:05,509] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:28:05,619] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:28:05,774] INFO [RaftManager id=5] Completed transition to Unattached(epoch=190, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=189, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1282, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:28:05,940] INFO [RaftManager id=5] Completed transition to Unattached(epoch=191, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=190, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:28:05,974] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:28:06,308] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=191, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1282, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=191, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:28:06,390] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:28:06,965] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:28:06,967] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:28:07,057] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:29:00,427] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:29:00,546] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1367 due to node 1 being disconnected (elapsed time since creation: 2182ms, elapsed time since send: 2022ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:29:00,956] INFO [RaftManager id=5] Completed transition to Unattached(epoch=192, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=191, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1377, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:29:01,072] WARN [BrokerLifecycleManager id=5] Broker 5 sent a heartbeat request but received error REQUEST_TIMED_OUT. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:29:01,451] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:29:02,940] INFO [RaftManager id=5] Completed transition to Unattached(epoch=193, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=192, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:29:04,157] INFO [RaftManager id=5] Completed transition to Unattached(epoch=194, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=193, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:29:04,329] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=194, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1377, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=194, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:29:04,391] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:31:58,975] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:31:59,778] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1712 due to node 1 being disconnected (elapsed time since creation: 2932ms, elapsed time since send: 2033ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:01,739] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:01,967] INFO [RaftManager id=5] Completed transition to Unattached(epoch=195, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=194, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:02,196] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 398 due to node 1 being disconnected (elapsed time since creation: 5096ms, elapsed time since send: 5095ms, throttle time: 0ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:02,467] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:09,180] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:13,059] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:13,156] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1718 due to node 3 being disconnected (elapsed time since creation: 4906ms, elapsed time since send: 2480ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:14,344] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:18,278] INFO [RaftManager id=5] Completed transition to Unattached(epoch=201, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=195, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:19,294] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:21,280] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:21,420] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1724 due to node 1 being disconnected (elapsed time since creation: 2737ms, elapsed time since send: 2736ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:25,142] INFO [RaftManager id=5] Completed transition to Unattached(epoch=203, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=201, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:26,082] INFO [RaftManager id=5] Completed transition to Unattached(epoch=204, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=203, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:26,257] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:30,611] INFO [RaftManager id=5] Completed transition to Unattached(epoch=206, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=204, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:34,041] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:36,060] INFO [RaftManager id=5] Completed transition to Unattached(epoch=207, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=206, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:40,723] INFO [RaftManager id=5] Completed transition to Unattached(epoch=209, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=207, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:42,780] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:43,724] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=211, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=209, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:43,827] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:32:46,622] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:48,003] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1734 due to node 1 being disconnected (elapsed time since creation: 2311ms, elapsed time since send: 2149ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:52,496] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:32:53,115] INFO [RaftManager id=5] Completed transition to Unattached(epoch=216, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=211, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:54,588] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:32:55,891] INFO [RaftManager id=5] Completed transition to Unattached(epoch=217, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=216, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:56,085] INFO [RaftManager id=5] Completed transition to Unattached(epoch=219, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=217, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:32:56,905] INFO [RaftManager id=5] Completed transition to Unattached(epoch=220, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=219, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:00,091] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:00,518] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1742 due to node 1 being disconnected (elapsed time since creation: 2455ms, elapsed time since send: 2453ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:02,506] INFO [RaftManager id=5] Completed transition to Unattached(epoch=224, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=220, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:05,292] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:05,394] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1749 due to node 3 being disconnected (elapsed time since creation: 2584ms, elapsed time since send: 2583ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:09,960] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:33:10,714] INFO [RaftManager id=5] Completed transition to Unattached(epoch=226, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=224, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:16,841] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:18,057] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1753 due to node 1 being disconnected (elapsed time since creation: 4085ms, elapsed time since send: 3939ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:18,153] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:18,206] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 1754 due to node 3 being disconnected (elapsed time since creation: 2057ms, elapsed time since send: 2053ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:20,008] INFO [RaftManager id=5] Completed transition to Unattached(epoch=232, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=226, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:20,769] INFO [RaftManager id=5] Completed transition to Unattached(epoch=233, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=232, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:22,635] INFO [RaftManager id=5] Completed transition to Unattached(epoch=236, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=233, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:24,287] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:33:25,221] INFO [RaftManager id=5] Completed transition to Unattached(epoch=237, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=236, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:25,369] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:33:25,376] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=238, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=237, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:35,018] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:35,052] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:33:35,109] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:33:35,910] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:36,010] INFO [RaftManager id=5] Completed transition to Unattached(epoch=242, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=238, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:38,279] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:33:39,039] INFO [RaftManager id=5] Completed transition to Unattached(epoch=244, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=242, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:42,552] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=246, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=244, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:43,059] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:33:43,269] INFO [RaftManager id=5] Completed transition to Unattached(epoch=247, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=246, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:43,650] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=247, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1700, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=247, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:33:49,331] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:33:49,521] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:00,005] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-21, __consumer_offsets-32, __consumer_offsets-40, __consumer_offsets-38, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-34, __consumer_offsets-47, _schemas-0, __consumer_offsets-16, __consumer_offsets-43, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-10, __consumer_offsets-24, __consumer_offsets-22, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-6, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:34:02,441] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-45, __consumer_offsets-14, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-28, __consumer_offsets-26, __consumer_offsets-39, __consumer_offsets-7, __consumer_offsets-37, __consumer_offsets-5, __consumer_offsets-35, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:34:06,830] INFO [ReplicaFetcherThread-0-6]: Starting (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,101] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-45 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,145] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 6 for partitions HashMap(__consumer_offsets-45 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-14 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-9 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-42 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-23 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-19 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-17 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-30 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-28 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-26 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-39 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-7 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-37 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-5 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),1,0), __consumer_offsets-35 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0), __consumer_offsets-1 -> InitialFetchState(Some(p0HtGUHKReOSVWe-VAlPVA),BrokerEndPoint(id=6, host=kafka-broker-3:19092),2,0)) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:34:07,189] INFO [UnifiedLog partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,221] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-14 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,222] INFO [UnifiedLog partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,223] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,240] INFO [UnifiedLog partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,281] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-42 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,288] INFO [UnifiedLog partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,320] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-23 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,324] INFO [UnifiedLog partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,339] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-19 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,345] INFO [UnifiedLog partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,346] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,347] INFO [UnifiedLog partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,347] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-30 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,349] INFO [UnifiedLog partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,344] INFO [ReplicaFetcherThread-0-4]: Shutting down (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,354] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-28 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,358] INFO [UnifiedLog partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,359] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,360] INFO [UnifiedLog partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,376] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-39 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,375] INFO [ReplicaFetcherThread-0-4]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,367] INFO [ReplicaFetcherThread-0-4]: Stopped (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,382] INFO [UnifiedLog partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,403] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,411] INFO [UnifiedLog partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,413] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-37 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,421] INFO [UnifiedLog partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,425] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,429] INFO [UnifiedLog partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,432] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,432] INFO [UnifiedLog partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:07,637] INFO [ReplicaFetcher replicaId=5, leaderId=6, fetcherId=0] Truncating partition __consumer_offsets-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2026-01-16 08:34:07,695] INFO [UnifiedLog partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2026-01-16 08:34:08,386] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 15 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,438] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,535] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 48 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,536] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,603] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 29 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,603] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-15 in 103 milliseconds for epoch 1, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,612] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,613] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds for epoch 1, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,616] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,631] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,639] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,656] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,657] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 24 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,659] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,659] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,659] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,659] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 38 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,659] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,660] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 33 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,675] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,682] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 2 in epoch 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,689] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,696] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,702] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,705] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,706] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,712] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,714] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,716] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,722] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,729] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,737] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,755] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,758] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,761] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,762] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,764] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,767] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,772] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,772] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,772] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,772] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,772] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,773] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,776] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,777] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,777] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,778] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,778] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,778] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,778] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,782] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:08,800] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:34:08,806] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:34:12,880] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, _schemas-0, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:34:14,832] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:14,934] INFO [RaftManager id=5] Completed transition to Unattached(epoch=248, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=247, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1877, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:34:15,024] INFO [RaftManager id=5] Completed transition to Unattached(epoch=249, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=248, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:34:15,878] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:16,104] INFO [RaftManager id=5] Completed transition to Unattached(epoch=251, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=249, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:34:17,938] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:34:18,294] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:18,360] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:18,500] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=251, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=1877, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=251, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:34:18,948] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:19,104] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:19,119] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:19,192] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:19,329] INFO [Partition __consumer_offsets-21 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=4, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=1, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=4, brokerEpoch=6)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:19,333] INFO [Partition __consumer_offsets-13 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=6, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=6, brokerEpoch=5)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:19,330] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:19,483] INFO [Partition __consumer_offsets-21 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=6, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=1, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=6, brokerEpoch=5)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:19,547] INFO [Partition __consumer_offsets-46 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=6, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=1, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=6, brokerEpoch=5)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:20,024] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:20,041] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:20,060] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:20,144] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:21,663] ERROR Encountered fatal fault: Unexpected error in raft IO thread (org.apache.kafka.server.fault.ProcessTerminatingFaultHandler)
org.apache.kafka.common.errors.CorruptRecordException: Record size 0 is less than the minimum record overhead (14)
[2026-01-16 08:34:22,286] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:22,279] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:34:21,814] INFO [Partition __consumer_offsets-16 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=4, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=4, brokerEpoch=6)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:26,192] INFO [Partition __consumer_offsets-16 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=6, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=6, brokerEpoch=5)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:26,267] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:26,381] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:34:26,398] INFO [Partition __consumer_offsets-13 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=4, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=4, brokerEpoch=6)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:34:26,578] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:34:26,693] INFO [Partition __consumer_offsets-13 broker=5] Failed to alter partition to PendingExpandIsr(newInSyncReplicaId=6, sentLeaderAndIsr=LeaderAndIsr(leader=5, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=5, brokerEpoch=7), BrokerState(brokerId=6, brokerEpoch=5)), leaderRecoveryState=RECOVERED, partitionEpoch=6), leaderRecoveryState=RECOVERED, lastCommittedState=CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED)) since the controller rejected the request with OPERATION_NOT_ATTEMPTED. Partition state has been reset to the latest committed state CommittedPartitionState(isr=Set(5), leaderRecoveryState=RECOVERED). (kafka.cluster.Partition)
[2026-01-16 08:35:27,020] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2026-01-16 08:35:30,030] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2026-01-16 08:35:30,078] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:35:32,690] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:35:33,056] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:35:33,338] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2026-01-16 08:35:33,399] INFO [BrokerServer id=5] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2026-01-16 08:35:33,495] INFO [SharedServer id=5] Starting SharedServer (kafka.server.SharedServer)
[2026-01-16 08:35:33,539] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:35:36,679] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
[2026-01-16 08:35:36,740] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:36,751] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:36,790] INFO Deleted producer state snapshot /tmp/kafka-logs/__cluster_metadata-0/00000000000000000788.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2026-01-16 08:35:36,818] INFO Deleted producer state snapshot /tmp/kafka-logs/__cluster_metadata-0/00000000000000000897.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2026-01-16 08:35:36,826] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 63ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:38,554] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 1879 with 0 producer ids in 66 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:35:39,071] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 1879 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:39,077] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 1879 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:39,078] INFO [ProducerStateManager partition=__cluster_metadata-0] Loading producer state from snapshot file 'SnapshotFile(offset=1879, file=/tmp/kafka-logs/__cluster_metadata-0/00000000000000001879.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:35:39,115] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 37ms for snapshot load and 0ms for segment recovery from offset 1879 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:41,555] INFO Initialized snapshots with IDs SortedSet() from /tmp/kafka-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2026-01-16 08:35:42,242] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2026-01-16 08:35:43,109] INFO [RaftManager id=5] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:35:46,026] INFO [RaftManager id=5] Starting request manager with static voters: [kafka-controller-1:9093 (id: 1 rack: null), kafka-controller-2:9093 (id: 2 rack: null), kafka-controller-3:9093 (id: 3 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:35:47,451] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=251, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:35:47,464] INFO [kafka-5-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2026-01-16 08:35:47,471] INFO [kafka-5-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2026-01-16 08:35:48,309] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:48,342] INFO [BrokerServer id=5] Starting broker (kafka.server.BrokerServer)
[2026-01-16 08:35:48,406] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:35:48,424] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:48,529] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:48,577] INFO [broker-5-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:35:48,578] INFO [broker-5-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:35:48,585] INFO [broker-5-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:35:48,631] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:48,653] INFO [broker-5-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2026-01-16 08:35:48,735] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:48,840] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:48,942] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,046] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,153] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,257] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,360] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,426] INFO [BrokerServer id=5] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-01-16 08:35:49,427] INFO [BrokerServer id=5] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2026-01-16 08:35:49,473] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,587] INFO [broker-5-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:35:49,588] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,609] INFO [broker-5-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:35:49,691] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,794] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:49,842] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2026-01-16 08:35:49,887] INFO [RaftManager id=5] Registered the listener org.apache.kafka.image.loader.MetadataLoader@203068561 (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:35:49,901] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,004] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,114] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,242] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,346] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,452] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,556] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,661] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,763] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,880] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:50,992] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:51,120] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:51,230] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:51,338] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:51,758] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:51,881] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:51,984] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:52,085] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:52,194] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:52,322] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:52,432] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,064] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,188] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,359] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,481] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,585] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,699] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:54,898] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,003] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,106] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,229] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,336] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,450] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,552] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,657] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,769] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,876] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:55,982] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,210] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,321] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,448] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,569] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,684] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,784] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=252, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=251, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:35:56,788] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:56,925] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,036] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,155] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,260] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,371] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,492] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,586] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Truncating to offset 1877 (kafka.log.UnifiedLog)
[2026-01-16 08:35:57,605] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,733] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,876] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:57,928] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 1877 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:57,953] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 1877 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:57,980] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,025] INFO Deleted producer state snapshot /tmp/kafka-logs/__cluster_metadata-0/00000000000000001879.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2026-01-16 08:35:58,086] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,298] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,405] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,488] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 1877 with 0 producer ids in 109 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:35:58,512] INFO [UnifiedLog partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 188ms for snapshot load and 367ms for segment recovery from offset 1877 (kafka.log.UnifiedLog$)
[2026-01-16 08:35:58,517] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,587] INFO [RaftManager id=5] Truncated to offset 1877 from Fetch response from leader 2 (org.apache.kafka.raft.KafkaRaftClient)
[2026-01-16 08:35:58,632] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,738] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,847] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:58,977] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,095] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,238] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,342] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,572] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,699] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,820] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:35:59,925] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,076] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,238] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,342] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,454] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,562] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,666] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,769] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,882] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:00,996] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:01,098] INFO [MetadataLoader id=5] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:01,157] INFO [RaftManager id=5] High watermark set to Optional[LogOffsetMetadata(offset=2116, metadata=Optional.empty)] for the first time for epoch 252 (org.apache.kafka.raft.FollowerState)
[2026-01-16 08:36:01,235] INFO [MetadataLoader id=5] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 2116 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:01,427] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-01-16 08:36:01,528] INFO [MetadataLoader id=5] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 0, but the high water mark is 2116 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:02,068] INFO [SocketServer listenerType=BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2026-01-16 08:36:02,116] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2026-01-16 08:36:02,195] INFO [SocketServer listenerType=BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_HOST) (kafka.network.SocketServer)
[2026-01-16 08:36:02,521] INFO [broker-5-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:02,537] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:02,903] INFO [broker-5-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:02,913] INFO [broker-5-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:03,632] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:03,655] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:03,676] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:03,729] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:03,794] INFO [ExpirationReaper-5-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:03,854] INFO [MetadataLoader id=5] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 2115, but the high water mark is 2125 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:03,863] INFO [MetadataLoader id=5] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 2115, but the high water mark is 2125 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:03,877] INFO [MetadataLoader id=5] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 2125 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:04,106] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 2124 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:04,488] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:04,503] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:05,305] INFO Unable to read the broker epoch in /tmp/kafka-logs. (kafka.log.LogManager)
[2026-01-16 08:36:05,321] INFO [broker-5-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:05,322] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:05,541] INFO [BrokerLifecycleManager id=5] Incarnation ZXblmrWfRaCCbam7HP7S3Q of broker 5 in cluster 5L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:06,213] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2026-01-16 08:36:08,238] INFO [BrokerLifecycleManager id=5] Successfully registered broker 5 with broker epoch 2131 (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:08,363] INFO [BrokerLifecycleManager id=5] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:08,453] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:09,335] INFO [BrokerServer id=5] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-01-16 08:36:09,344] INFO [BrokerServer id=5] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2026-01-16 08:36:09,382] INFO [BrokerServer id=5] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-01-16 08:36:09,397] INFO [BrokerServer id=5] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2026-01-16 08:36:09,403] INFO [BrokerServer id=5] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-01-16 08:36:09,458] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing MetadataVersionPublisher(id=5) with a snapshot at offset 2135 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:09,476] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 2135 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:36:09,563] INFO [BrokerMetadataPublisher id=5] Publishing initial metadata at offset OffsetAndEpoch(offset=2135, epoch=252) with metadata.version 3.8-IV0. (kafka.server.metadata.BrokerMetadataPublisher)
[2026-01-16 08:36:09,726] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:10,292] INFO Recovering 51 logs from /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2026-01-16 08:36:10,573] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:10,789] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-28. (kafka.log.LogLoader)
[2026-01-16 08:36:10,832] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:10,861] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:10,871] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,048] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,064] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,121] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,582] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-28, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 858ms (1/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:11,669] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-2. (kafka.log.LogLoader)
[2026-01-16 08:36:11,677] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,679] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,684] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,807] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,817] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,821] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:11,921] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-2, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 321ms (2/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:12,074] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-27. (kafka.log.LogLoader)
[2026-01-16 08:36:12,098] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,104] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,108] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,149] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,151] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,152] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,227] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 300ms (3/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:12,268] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-13. (kafka.log.LogLoader)
[2026-01-16 08:36:12,277] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,303] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,315] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,447] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,493] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,494] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,563] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-13, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 301ms (4/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:12,690] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:12,778] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-8. (kafka.log.LogLoader)
[2026-01-16 08:36:12,788] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,792] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,796] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,842] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,847] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:12,848] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:13,019] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-8, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 444ms (5/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:13,062] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for _schemas-0. (kafka.log.LogLoader)
[2026-01-16 08:36:13,062] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:13,062] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:13,062] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:13,127] INFO [ProducerStateManager partition=_schemas-0] Wrote producer snapshot at offset 2 with 0 producer ids in 35 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:36:13,266] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:16,144] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:16,178] INFO [ProducerStateManager partition=_schemas-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/tmp/kafka-logs/_schemas-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:36:16,377] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:16,477] INFO [LogLoader partition=_schemas-0, dir=/tmp/kafka-logs] Producer state recovery took 299ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:17,033] INFO Completed load of Log(dir=/tmp/kafka-logs/_schemas-0, topicId=UjN16IrSRlipZQeCwkGrdQ, topic=_schemas, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 3991ms (6/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:18,282] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-37. (kafka.log.LogLoader)
[2026-01-16 08:36:18,415] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:18,433] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:18,441] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:18,446] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:18,560] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:18,567] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:18,592] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:18,864] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-37, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1807ms (7/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:19,270] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-25. (kafka.log.LogLoader)
[2026-01-16 08:36:19,273] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,308] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,325] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Producer state recovery took 15ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,426] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,437] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,448] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,653] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-25, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 679ms (8/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:19,788] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-17. (kafka.log.LogLoader)
[2026-01-16 08:36:19,804] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,809] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,810] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,861] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,925] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:19,954] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,160] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-17, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 483ms (9/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:20,281] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-20. (kafka.log.LogLoader)
[2026-01-16 08:36:20,290] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,293] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,293] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,319] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,327] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,333] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,352] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-20, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 163ms (10/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:20,398] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-48. (kafka.log.LogLoader)
[2026-01-16 08:36:20,403] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,410] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,410] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,440] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,442] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,446] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:20,555] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:20,615] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-48, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 234ms (11/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:20,948] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-11. (kafka.log.LogLoader)
[2026-01-16 08:36:20,956] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,015] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,035] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,054] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,070] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,071] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,088] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-11, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 463ms (12/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:21,118] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-34. (kafka.log.LogLoader)
[2026-01-16 08:36:21,129] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,137] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,141] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,298] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,327] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,349] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:21,629] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-34, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 540ms (13/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:21,911] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-26. (kafka.log.LogLoader)
[2026-01-16 08:36:22,050] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,142] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,155] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,438] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,445] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,446] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,506] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-26, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 779ms (14/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:22,692] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:22,746] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-32. (kafka.log.LogLoader)
[2026-01-16 08:36:22,756] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,762] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,765] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,790] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,812] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,815] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:22,863] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-32, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 353ms (15/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:23,019] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-23. (kafka.log.LogLoader)
[2026-01-16 08:36:23,070] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,074] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,078] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,113] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,113] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,113] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,123] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-23, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 250ms (16/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:23,151] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-45. (kafka.log.LogLoader)
[2026-01-16 08:36:23,151] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,157] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,157] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,168] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,169] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,169] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,179] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 50ms (17/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:23,198] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-31. (kafka.log.LogLoader)
[2026-01-16 08:36:23,199] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,205] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,209] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,226] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,236] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,245] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,301] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-31, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 121ms (18/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:23,354] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-36. (kafka.log.LogLoader)
[2026-01-16 08:36:23,359] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,363] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,365] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 2ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,376] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,377] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,379] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,389] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-36, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 78ms (19/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:23,416] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-15. (kafka.log.LogLoader)
[2026-01-16 08:36:23,441] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,442] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,443] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,471] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,476] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,478] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,531] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 141ms (20/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:23,564] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-1. (kafka.log.LogLoader)
[2026-01-16 08:36:23,574] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,575] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,575] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,619] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,633] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:23,637] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:24,493] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-1, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 943ms (21/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:24,767] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:25,096] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-18. (kafka.log.LogLoader)
[2026-01-16 08:36:25,098] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,126] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,148] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,356] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,361] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,367] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,473] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-18, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 910ms (22/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:25,633] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-7. (kafka.log.LogLoader)
[2026-01-16 08:36:25,649] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,666] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,675] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,684] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,685] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,686] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,692] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-7, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 200ms (23/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:25,816] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-35. (kafka.log.LogLoader)
[2026-01-16 08:36:25,818] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,820] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,821] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,836] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,839] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,844] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:25,886] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-35, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 194ms (24/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:25,981] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-42. (kafka.log.LogLoader)
[2026-01-16 08:36:26,008] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,030] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,030] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,152] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,172] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,176] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,189] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-42, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 297ms (25/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:26,211] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-0. (kafka.log.LogLoader)
[2026-01-16 08:36:26,213] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,214] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,214] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,257] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,271] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,276] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,287] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-0, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 96ms (26/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:26,303] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-33. (kafka.log.LogLoader)
[2026-01-16 08:36:26,310] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,311] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,315] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,418] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,419] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,419] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,426] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 137ms (27/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:26,462] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-30. (kafka.log.LogLoader)
[2026-01-16 08:36:26,474] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,478] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,479] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,598] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,625] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,628] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,716] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-30, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 273ms (28/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:26,906] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:26,907] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-46. (kafka.log.LogLoader)
[2026-01-16 08:36:26,920] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,943] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,946] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,991] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,996] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:26,999] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,035] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-46, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 306ms (29/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:27,195] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-29. (kafka.log.LogLoader)
[2026-01-16 08:36:27,253] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,267] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,268] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,328] INFO [ProducerStateManager partition=__consumer_offsets-29] Wrote producer snapshot at offset 1 with 0 producer ids in 37 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:36:27,373] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,379] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,382] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=/tmp/kafka-logs/__consumer_offsets-29/00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2026-01-16 08:36:27,389] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,433] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-29, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 379ms (30/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:27,480] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-47. (kafka.log.LogLoader)
[2026-01-16 08:36:27,495] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,504] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,530] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 24ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,736] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,761] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,764] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:27,831] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-47, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 386ms (31/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:28,292] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-41. (kafka.log.LogLoader)
[2026-01-16 08:36:28,331] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:28,354] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:28,360] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:28,585] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:28,603] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:28,603] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:28,819] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-41, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 929ms (32/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:29,152] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:29,193] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-9. (kafka.log.LogLoader)
[2026-01-16 08:36:29,373] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:29,384] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:29,450] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:29,493] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:29,571] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:29,578] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:29,936] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1089ms (33/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:30,072] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-12. (kafka.log.LogLoader)
[2026-01-16 08:36:30,080] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,082] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,095] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 10ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,120] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,124] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,131] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,392] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-12, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 453ms (34/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:30,652] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-21. (kafka.log.LogLoader)
[2026-01-16 08:36:30,654] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,663] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,679] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,725] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,730] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,740] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:30,861] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 407ms (35/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:31,170] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-19. (kafka.log.LogLoader)
[2026-01-16 08:36:31,185] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:31,187] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:31,204] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:31,301] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:31,316] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:31,317] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:35,663] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:36,019] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-19, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4838ms (36/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:36,202] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-3. (kafka.log.LogLoader)
[2026-01-16 08:36:36,217] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,223] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,228] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,294] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,304] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,311] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,355] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 329ms (37/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:36,586] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-14. (kafka.log.LogLoader)
[2026-01-16 08:36:36,628] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,630] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,632] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,673] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,676] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,677] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,723] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-14, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 364ms (38/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:36,864] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-10. (kafka.log.LogLoader)
[2026-01-16 08:36:36,884] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,887] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,892] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,957] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,959] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:36,959] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,008] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-10, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 274ms (39/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:37,111] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-5. (kafka.log.LogLoader)
[2026-01-16 08:36:37,116] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,118] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,119] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,158] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,173] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,173] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,323] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-5, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 207ms (40/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:37,700] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-24. (kafka.log.LogLoader)
[2026-01-16 08:36:37,743] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,782] INFO [RaftManager id=5] Completed transition to Unattached(epoch=253, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=252, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2173, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:36:37,919] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:37,941] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:38,271] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:38,415] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:38,448] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:38,883] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:36:39,085] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-24, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1724ms (41/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:40,370] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-39. (kafka.log.LogLoader)
[2026-01-16 08:36:40,797] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:40,807] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:40,810] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:41,084] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:41,142] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:41,143] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:41,673] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=257, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2173, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=253, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:36:41,758] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:43,178] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3958ms (42/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:43,401] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:36:43,404] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:43,470] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-4. (kafka.log.LogLoader)
[2026-01-16 08:36:43,474] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:43,480] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:43,482] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:43,911] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:44,106] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:44,153] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:44,175] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:44,210] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:36:44,319] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:44,732] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:36:44,767] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:45,462] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-4, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2168ms (43/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:45,533] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:36:45,553] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:45,631] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=258, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2173, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=257, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2173, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:36:45,637] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:36:46,153] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-38. (kafka.log.LogLoader)
[2026-01-16 08:36:46,165] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:46,167] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:46,170] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:46,252] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:46,308] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:46,450] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:46,718] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-38, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1209ms (44/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:46,735] INFO [BrokerLifecycleManager id=5] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:36:47,016] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-44. (kafka.log.LogLoader)
[2026-01-16 08:36:47,035] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,042] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,043] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,087] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,089] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,091] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,132] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-44, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 391ms (45/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:47,219] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-22. (kafka.log.LogLoader)
[2026-01-16 08:36:47,235] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,243] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,256] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,293] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,294] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,294] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:47,582] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-22, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 448ms (46/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:36:48,023] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-43. (kafka.log.LogLoader)
[2026-01-16 08:36:48,057] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:48,063] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:48,064] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:50,433] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:50,685] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:50,836] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:36:53,211] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:01,417] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:01,546] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-43, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13663ms (47/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:37:02,186] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 10475ms, elapsed time since send: 10391ms, throttle time: 0ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:02,347] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 77 due to node 2 being disconnected (elapsed time since creation: 2698ms, elapsed time since send: 2226ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:02,647] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:37:02,948] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:06,522] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-40. (kafka.log.LogLoader)
[2026-01-16 08:37:08,276] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:08,371] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:08,537] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Producer state recovery took 118ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:08,979] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:08,985] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:09,049] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:09,120] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:37:09,376] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:10,639] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:10,695] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:37:10,820] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-40, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8519ms (48/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:37:12,497] INFO [RaftManager id=5] Completed transition to Unattached(epoch=267, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=258, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:37:14,322] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 1 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:17,458] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:18,487] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-6. (kafka.log.LogLoader)
[2026-01-16 08:37:18,740] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:18,746] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:18,764] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:19,483] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:19,829] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 85 due to node 2 being disconnected (elapsed time since creation: 4526ms, elapsed time since send: 3450ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:25,776] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:26,978] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:27,015] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:27,023] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:28,494] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:31,989] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 87 due to node 1 being disconnected (elapsed time since creation: 7080ms, elapsed time since send: 6738ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:34,667] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:35,300] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-6, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24043ms (49/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:37:38,826] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-49. (kafka.log.LogLoader)
[2026-01-16 08:37:39,364] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:39,391] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:39,392] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:40,563] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:40,643] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:40,668] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:40,802] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:40,884] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 92 due to node 3 being disconnected (elapsed time since creation: 7692ms, elapsed time since send: 2228ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:42,187] INFO [RaftManager id=5] Completed transition to Unattached(epoch=276, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=267, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:37:42,259] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-49, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5431ms (50/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:37:43,218] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:45,855] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-16. (kafka.log.LogLoader)
[2026-01-16 08:37:46,341] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:46,398] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:46,398] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:47,738] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:47,998] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:48,008] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2026-01-16 08:37:53,481] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:37:53,962] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:54,605] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 99 due to node 2 being disconnected (elapsed time since creation: 5586ms, elapsed time since send: 3937ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:37:58,275] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-16, topicId=p0HtGUHKReOSVWe-VAlPVA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15586ms (51/51 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2026-01-16 08:38:00,741] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:01,223] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 102 due to node 2 being disconnected (elapsed time since creation: 2072ms, elapsed time since send: 2072ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:05,721] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:05,843] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:38:08,017] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 104 due to node 1 being disconnected (elapsed time since creation: 5281ms, elapsed time since send: 2571ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:11,704] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:12,113] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 107 due to node 2 being disconnected (elapsed time since creation: 7543ms, elapsed time since send: 7543ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:12,115] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:12,120] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 108 due to node 3 being disconnected (elapsed time since creation: 4944ms, elapsed time since send: 2654ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:14,333] INFO Loaded 51 logs in 121772ms (unclean log dirs = ArrayBuffer(/tmp/kafka-logs)) (kafka.log.LogManager)
[2026-01-16 08:38:19,007] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:20,057] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 110 due to node 2 being disconnected (elapsed time since creation: 5471ms, elapsed time since send: 3632ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:20,874] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:21,741] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2026-01-16 08:38:22,239] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 112 due to node 3 being disconnected (elapsed time since creation: 4880ms, elapsed time since send: 4880ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:23,278] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:38:26,806] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:29,767] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 115 due to node 3 being disconnected (elapsed time since creation: 3592ms, elapsed time since send: 3592ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:39,471] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2026-01-16 08:38:40,795] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:38:43,616] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:44,064] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 118 due to node 3 being disconnected (elapsed time since creation: 2297ms, elapsed time since send: 2297ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:51,658] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:52,316] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 122 due to node 2 being disconnected (elapsed time since creation: 4443ms, elapsed time since send: 3528ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:55,783] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:38:59,245] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:38:59,677] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 124 due to node 3 being disconnected (elapsed time since creation: 4529ms, elapsed time since send: 4529ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:39:04,060] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:39:05,144] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 128 due to node 1 being disconnected (elapsed time since creation: 6462ms, elapsed time since send: 2492ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:39:13,434] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:39:17,838] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:39:20,163] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 135 due to node 2 being disconnected (elapsed time since creation: 2024ms, elapsed time since send: 2024ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:39:30,587] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:39:50,245] INFO [RaftManager id=5] Completed transition to Unattached(epoch=317, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=276, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:39:52,480] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:39:52,665] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2026-01-16 08:39:53,164] INFO [RaftManager id=5] Completed transition to Unattached(epoch=319, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=317, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:39:53,257] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2026-01-16 08:39:53,310] INFO [AddPartitionsToTxnSenderThread-5]: Starting (kafka.server.AddPartitionsToTxnManager)
[2026-01-16 08:39:54,225] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:39:55,780] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:40:00,455] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:40:00,641] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 151 due to node 3 being disconnected (elapsed time since creation: 2097ms, elapsed time since send: 2068ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:40:01,572] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-01-16 08:40:01,964] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2026-01-16 08:40:01,984] INFO [TxnMarkerSenderThread-5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2026-01-16 08:40:06,387] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:40:07,689] INFO [RaftManager id=5] Completed transition to Unattached(epoch=326, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=319, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:11,333] INFO [Partition __consumer_offsets-13 broker=5] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:16,385] INFO [RaftManager id=5] Completed transition to Unattached(epoch=329, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=326, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:20,570] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:20,816] INFO [RaftManager id=5] Completed transition to Unattached(epoch=334, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=329, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:20,997] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:40:23,293] INFO [Partition __consumer_offsets-9 broker=5] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:30,981] INFO [RaftManager id=5] Completed transition to Unattached(epoch=338, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=334, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:32,811] INFO [Partition __consumer_offsets-42 broker=5] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:35,660] INFO [RaftManager id=5] Completed transition to Unattached(epoch=342, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=338, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:35,940] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:40:36,380] INFO [Partition __consumer_offsets-21 broker=5] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:36,517] INFO [Partition __consumer_offsets-17 broker=5] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:37,702] INFO [Partition __consumer_offsets-30 broker=5] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:37,908] INFO [Partition __consumer_offsets-26 broker=5] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:37,921] INFO [Partition __consumer_offsets-5 broker=5] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:37,955] INFO [Partition __consumer_offsets-38 broker=5] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:37,970] INFO [Partition __consumer_offsets-1 broker=5] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:37,988] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:38,016] INFO [Partition _schemas-0 broker=5] Log loaded for partition _schemas-0 with initial high watermark 2 (kafka.cluster.Partition)
[2026-01-16 08:40:38,215] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:38,769] INFO [Partition __consumer_offsets-45 broker=5] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:39,987] INFO [Partition __consumer_offsets-12 broker=5] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:43,045] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=345, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=342, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:43,360] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:40:44,917] INFO [Partition __consumer_offsets-41 broker=5] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:49,316] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:40:49,910] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:40:50,215] INFO [Partition __consumer_offsets-24 broker=5] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:50,232] INFO [RaftManager id=5] Completed transition to Unattached(epoch=349, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=345, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:51,532] INFO [Partition __consumer_offsets-20 broker=5] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:40:56,334] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:40:58,489] INFO [RaftManager id=5] Completed transition to Unattached(epoch=350, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=349, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:40:58,660] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:41:00,972] INFO [Partition __consumer_offsets-49 broker=5] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:03,536] INFO [Partition __consumer_offsets-0 broker=5] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:03,649] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:05,659] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 165 due to node 2 being disconnected (elapsed time since creation: 3608ms, elapsed time since send: 2207ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:07,439] INFO [Partition __consumer_offsets-29 broker=5] Log loaded for partition __consumer_offsets-29 with initial high watermark 1 (kafka.cluster.Partition)
[2026-01-16 08:41:07,947] INFO [Partition __consumer_offsets-25 broker=5] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:08,177] INFO [Partition __consumer_offsets-8 broker=5] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:08,475] INFO [Partition __consumer_offsets-37 broker=5] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:08,622] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:08,809] INFO [Partition __consumer_offsets-33 broker=5] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:11,639] INFO [RaftManager id=5] Completed transition to Unattached(epoch=359, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=350, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:41:12,952] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:41:16,936] INFO [Partition __consumer_offsets-15 broker=5] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:26,291] INFO [Partition __consumer_offsets-48 broker=5] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:30,145] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:41:30,618] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:31,582] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 174 due to node 1 being disconnected (elapsed time since creation: 5304ms, elapsed time since send: 3538ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:32,536] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:32,674] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 173 due to node 3 being disconnected (elapsed time since creation: 7325ms, elapsed time since send: 5988ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:33,159] INFO [Partition __consumer_offsets-11 broker=5] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:35,408] INFO [Partition __consumer_offsets-44 broker=5] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:36,312] INFO [Partition __consumer_offsets-23 broker=5] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:42,529] INFO [Partition __consumer_offsets-19 broker=5] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:44,925] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:45,318] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:41:46,048] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 177 due to node 1 being disconnected (elapsed time since creation: 2841ms, elapsed time since send: 2841ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:46,337] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:46,380] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 178 due to node 3 being disconnected (elapsed time since creation: 2841ms, elapsed time since send: 2841ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:41:49,722] INFO [Partition __consumer_offsets-32 broker=5] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:41:54,727] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:00,519] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 185 due to node 3 being disconnected (elapsed time since creation: 6695ms, elapsed time since send: 3457ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:02,363] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:04,417] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:42:05,786] INFO [Partition __consumer_offsets-7 broker=5] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:07,183] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:07,257] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 188 due to node 2 being disconnected (elapsed time since creation: 5535ms, elapsed time since send: 3348ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:07,281] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:09,794] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:10,078] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 190 due to node 3 being disconnected (elapsed time since creation: 4433ms, elapsed time since send: 4433ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:10,197] INFO [Partition __consumer_offsets-3 broker=5] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:11,417] INFO [Partition __consumer_offsets-36 broker=5] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:12,938] INFO [Partition __consumer_offsets-47 broker=5] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:17,929] INFO [Partition __consumer_offsets-14 broker=5] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:19,431] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:42:20,093] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:20,284] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 194 due to node 2 being disconnected (elapsed time since creation: 3309ms, elapsed time since send: 3309ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:24,977] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:25,293] INFO [Partition __consumer_offsets-43 broker=5] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:28,651] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 196 due to node 1 being disconnected (elapsed time since creation: 8828ms, elapsed time since send: 8828ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:32,245] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:32,323] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 199 due to node 2 being disconnected (elapsed time since creation: 6380ms, elapsed time since send: 6380ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:32,345] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:36,779] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:42:37,228] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 200 due to node 3 being disconnected (elapsed time since creation: 6380ms, elapsed time since send: 6380ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:37,464] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:37,544] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:37,958] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:38,017] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 204 due to node 1 being disconnected (elapsed time since creation: 6950ms, elapsed time since send: 6950ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:42:38,194] INFO [Partition __consumer_offsets-18 broker=5] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:38,450] INFO [Partition __consumer_offsets-31 broker=5] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:39,184] INFO [Partition __consumer_offsets-27 broker=5] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:39,789] INFO [Partition __consumer_offsets-39 broker=5] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:40,810] INFO [Partition __consumer_offsets-6 broker=5] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:41,878] INFO [Partition __consumer_offsets-35 broker=5] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:45,393] INFO [Partition __consumer_offsets-2 broker=5] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2026-01-16 08:42:51,786] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:42:59,882] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:00,586] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, _schemas-0, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:43:01,355] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 211 due to node 1 being disconnected (elapsed time since creation: 5883ms, elapsed time since send: 5883ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:06,050] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:43:09,808] INFO [RaftManager id=5] Completed transition to Unattached(epoch=389, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=359, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:43:10,322] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:10,494] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 219 due to node 2 being disconnected (elapsed time since creation: 5211ms, elapsed time since send: 3641ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:12,592] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:12,629] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 221 due to node 1 being disconnected (elapsed time since creation: 2548ms, elapsed time since send: 2023ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:17,975] INFO [RaftManager id=5] Completed transition to Unattached(epoch=392, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=389, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:43:22,522] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:43:23,112] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:23,176] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 223 due to node 3 being disconnected (elapsed time since creation: 3453ms, elapsed time since send: 2070ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:25,627] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:25,811] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 225 due to node 1 being disconnected (elapsed time since creation: 3640ms, elapsed time since send: 3640ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:36,093] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:37,285] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 231 due to node 3 being disconnected (elapsed time since creation: 6377ms, elapsed time since send: 5800ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:38,924] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:43:43,330] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:44,561] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 233 due to node 3 being disconnected (elapsed time since creation: 5011ms, elapsed time since send: 5011ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:52,531] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:52,813] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 235 due to node 2 being disconnected (elapsed time since creation: 8995ms, elapsed time since send: 3276ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:43:58,280] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:44:07,006] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:44:07,304] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 240 due to node 1 being disconnected (elapsed time since creation: 6188ms, elapsed time since send: 4279ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:44:07,819] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:44:07,829] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 242 due to node 2 being disconnected (elapsed time since creation: 5516ms, elapsed time since send: 5516ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:44:15,031] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:44:17,705] INFO [RaftManager id=5] Completed transition to Unattached(epoch=400, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=392, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:44:24,946] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:44:25,288] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 247 due to node 3 being disconnected (elapsed time since creation: 6893ms, elapsed time since send: 3252ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:44:30,708] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:44:35,342] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:40,153] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,359] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,380] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,384] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,386] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,409] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,414] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,420] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 21 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,460] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,469] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,481] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,483] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,484] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,485] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,486] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,487] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,509] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,511] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,554] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,610] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,656] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,706] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 34 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,708] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,709] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,709] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,710] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,712] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,714] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,716] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,716] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,716] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,716] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,717] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,717] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,717] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,717] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,717] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,718] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 0 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,718] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,718] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,718] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,718] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,718] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,719] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,719] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,725] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,726] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,727] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,728] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,729] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,729] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,729] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,730] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,731] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,731] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,736] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 11 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,741] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,746] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 44 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,751] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,752] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,753] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,754] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,755] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,761] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,762] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,763] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,765] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,769] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,779] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,780] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,781] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,784] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,784] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,790] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 36 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,791] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,791] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,792] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,793] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,793] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,796] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,801] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,802] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,803] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,809] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 22 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,811] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,814] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,815] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,816] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,816] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,817] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 27 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,818] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,821] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,829] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,836] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[1] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,836] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,836] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,837] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:41,842] INFO [GroupCoordinator 5]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:44:41,842] INFO [GroupMetadataManager brokerId=5] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:45,196] INFO [RaftManager id=5] Completed transition to Unattached(epoch=406, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=400, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:44:47,744] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:44:52,476] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:53,572] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:59,259] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:44:59,302] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:00,273] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,283] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-21 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,304] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,306] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,491] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 254 due to node 1 being disconnected (elapsed time since creation: 9331ms, elapsed time since send: 7967ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:00,496] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,732] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,763] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,780] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,784] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-34 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,785] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,898] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:00,973] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,226] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,236] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,278] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,279] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,284] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-0 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,284] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,293] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,321] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,409] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,509] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,560] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,605] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,643] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,649] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-11 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,780] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-44 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,810] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,964] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:01,978] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,033] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,067] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,091] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,245] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,260] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-36 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,387] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,391] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,410] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,410] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,423] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-22 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,426] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,429] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,433] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-27 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,439] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,443] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[1]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,451] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:02,452] INFO [GroupMetadataManager brokerId=5] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:45:08,151] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:45:15,352] INFO [DynamicConfigPublisher broker id=5] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
[2026-01-16 08:45:20,815] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:22,067] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 262 due to node 2 being disconnected (elapsed time since creation: 7380ms, elapsed time since send: 2803ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:22,312] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:22,315] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 263 due to node 3 being disconnected (elapsed time since creation: 5093ms, elapsed time since send: 4637ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:24,371] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:45:28,516] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:32,858] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 266 due to node 1 being disconnected (elapsed time since creation: 2675ms, elapsed time since send: 2675ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:45:39,956] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:45:54,065] INFO [DynamicConfigPublisher broker id=5] Updating topic _schemas with new configuration : cleanup.policy -> compact (kafka.server.metadata.DynamicConfigPublisher)
[2026-01-16 08:45:54,969] INFO [RaftManager id=5] Completed transition to Unattached(epoch=417, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=406, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:45:56,984] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:45:58,431] INFO [RaftManager id=5] Completed transition to Unattached(epoch=419, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=417, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:05,846] INFO [RaftManager id=5] Completed transition to Unattached(epoch=422, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=419, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:06,079] INFO [BrokerServer id=5] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2026-01-16 08:46:06,082] INFO [MetadataLoader id=5] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=5) with a snapshot at offset 2135 (org.apache.kafka.image.loader.MetadataLoader)
[2026-01-16 08:46:07,342] INFO KafkaConfig values: 
	advertised.listeners = PLAINTEXT://kafka-broker-2:19092,PLAINTEXT_HOST://localhost:39092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@kafka-controller-1:9093, 2@kafka-controller-2:9093, 3@kafka-controller-3:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = PLAINTEXT
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
	listeners = PLAINTEXT://:19092,PLAINTEXT_HOST://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2026-01-16 08:46:07,759] INFO [RaftManager id=5] Completed transition to Unattached(epoch=423, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=422, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:08,708] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2026-01-16 08:46:09,828] INFO [RaftManager id=5] Completed transition to Unattached(epoch=425, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=423, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:09,934] INFO [RaftManager id=5] Completed transition to Unattached(epoch=426, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=425, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:12,083] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:46:12,124] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:46:12,346] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 284 due to node 3 being disconnected (elapsed time since creation: 2077ms, elapsed time since send: 2072ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:46:12,431] INFO [BrokerServer id=5] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-01-16 08:46:17,440] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:46:17,440] INFO [RaftManager id=5] Completed transition to Unattached(epoch=429, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=426, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:18,371] INFO [RaftManager id=5] Completed transition to Unattached(epoch=431, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=429, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:21,454] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:46:22,720] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 290 due to node 2 being disconnected (elapsed time since creation: 2178ms, elapsed time since send: 2177ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:46:29,486] INFO [RaftManager id=5] Completed transition to Unattached(epoch=435, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=431, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:31,130] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:46:34,340] INFO [RaftManager id=5] Completed transition to Unattached(epoch=439, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=435, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:35,584] INFO [RaftManager id=5] Completed transition to Unattached(epoch=440, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=439, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:36,076] INFO [RaftManager id=5] Completed transition to Unattached(epoch=441, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=440, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:36,659] INFO [RaftManager id=5] Completed transition to Unattached(epoch=442, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=441, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:42,531] INFO [RaftManager id=5] Completed transition to Unattached(epoch=444, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=442, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:45,476] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:46:50,667] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=448, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=444, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:51,341] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:46:54,690] INFO [RaftManager id=5] Completed transition to Unattached(epoch=451, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=448, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:55,705] INFO [RaftManager id=5] Completed transition to Unattached(epoch=452, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=451, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:56,593] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:46:56,615] INFO [RaftManager id=5] Completed transition to Unattached(epoch=453, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=452, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:46:59,099] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:47:02,083] INFO [RaftManager id=5] Completed transition to Unattached(epoch=455, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=453, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:05,285] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:47:05,674] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 309 due to node 2 being disconnected (elapsed time since creation: 2842ms, elapsed time since send: 2791ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:47:09,502] INFO [RaftManager id=5] Completed transition to Unattached(epoch=457, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=455, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:12,168] INFO [RaftManager id=5] Completed transition to Unattached(epoch=461, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=457, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:13,690] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:47:14,201] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=463, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=461, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:14,376] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:47:14,392] INFO [RaftManager id=5] Completed transition to Unattached(epoch=464, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=463, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:16,904] INFO [RaftManager id=5] Completed transition to Unattached(epoch=466, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=464, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:18,529] INFO [RaftManager id=5] Completed transition to Unattached(epoch=468, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=466, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:20,266] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=469, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=468, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:26,190] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:47:26,390] INFO [RaftManager id=5] Completed transition to Unattached(epoch=470, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=469, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:28,154] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:47:28,469] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=472, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=470, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:28,521] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:47:28,618] INFO [RaftManager id=5] Completed transition to Unattached(epoch=473, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=472, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:30,748] INFO [RaftManager id=5] Completed transition to Unattached(epoch=474, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=473, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:31,456] INFO [RaftManager id=5] Completed transition to Unattached(epoch=475, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=474, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:33,869] INFO [RaftManager id=5] Completed transition to Unattached(epoch=476, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=475, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:34,316] INFO [RaftManager id=5] Completed transition to Unattached(epoch=479, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=476, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:35,250] INFO [RaftManager id=5] Completed transition to Unattached(epoch=480, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=479, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:36,896] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=480, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=480, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:42,435] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:47:42,842] INFO [RaftManager id=5] Completed transition to Unattached(epoch=483, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=480, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:43,363] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:47:47,522] INFO [RaftManager id=5] Completed transition to Unattached(epoch=484, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=483, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:49,351] INFO [RaftManager id=5] Completed transition to Unattached(epoch=487, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=484, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:53,241] INFO [RaftManager id=5] Completed transition to Unattached(epoch=488, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=487, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:57,114] INFO [RaftManager id=5] Completed transition to Unattached(epoch=491, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=488, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:47:59,182] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:48:09,542] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:10,194] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 338 due to node 1 being disconnected (elapsed time since creation: 2191ms, elapsed time since send: 2016ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:13,548] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:13,689] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 339 due to node 2 being disconnected (elapsed time since creation: 3567ms, elapsed time since send: 2270ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:13,972] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:48:21,406] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:23,374] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 344 due to node 2 being disconnected (elapsed time since creation: 2458ms, elapsed time since send: 2458ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:30,264] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:48:31,135] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:31,753] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 346 due to node 1 being disconnected (elapsed time since creation: 3914ms, elapsed time since send: 2385ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:36,336] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:36,559] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 347 due to node 3 being disconnected (elapsed time since creation: 10893ms, elapsed time since send: 3453ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:39,355] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:39,663] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 350 due to node 1 being disconnected (elapsed time since creation: 3025ms, elapsed time since send: 3025ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:46,244] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:48:46,490] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:46,820] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 357 due to node 3 being disconnected (elapsed time since creation: 2099ms, elapsed time since send: 2016ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:48:52,359] INFO [RaftManager id=5] Completed transition to Unattached(epoch=517, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=491, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:48:59,394] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=517, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=517, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:49:01,530] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:49:01,920] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:49:06,353] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:49:07,351] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 362 due to node 3 being disconnected (elapsed time since creation: 3997ms, elapsed time since send: 3324ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:49:12,996] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:49:14,778] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:49:16,261] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=522, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=517, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:49:21,426] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:49:21,974] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:49:22,024] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:49:24,353] INFO [RaftManager id=5] Completed transition to Unattached(epoch=526, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=522, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:49:25,165] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=527, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=526, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:49:37,441] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:49:37,662] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:49:38,609] INFO [RaftManager id=5] Completed transition to Unattached(epoch=528, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=527, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:49:40,727] INFO [RaftManager id=5] Completed transition to Unattached(epoch=529, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=528, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:49:43,312] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=531, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2197, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=529, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:01,920] INFO [BrokerLifecycleManager id=5] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:01,957] INFO [BrokerServer id=5] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2026-01-16 08:50:04,123] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:08,187] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:50:08,516] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:08,595] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=535, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2292, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=531, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2292, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:16,367] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:17,086] INFO authorizerStart completed for endpoint PLAINTEXT_HOST. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-01-16 08:50:17,672] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2026-01-16 08:50:18,068] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:50:18,070] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:18,125] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 382 due to node 1 being disconnected (elapsed time since creation: 6527ms, elapsed time since send: 5694ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:21,290] INFO [SocketServer listenerType=BROKER, nodeId=5] Enabling request processing. (kafka.network.SocketServer)
[2026-01-16 08:50:21,728] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:21,476] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:21,920] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 383 due to node 2 being disconnected (elapsed time since creation: 8975ms, elapsed time since send: 3019ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:21,966] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:50:23,062] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:24,201] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:50:24,280] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:27,019] INFO [RaftManager id=5] Completed transition to Unattached(epoch=545, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=535, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2292, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:28,250] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:29,158] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2026-01-16 08:50:29,504] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:35,199] INFO [RaftManager id=5] Completed transition to Unattached(epoch=550, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=545, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:35,770] INFO Awaiting socket connections on 0.0.0.0:19092. (kafka.network.DataPlaneAcceptor)
[2026-01-16 08:50:39,572] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:40,147] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=551, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2292, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=550, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:40,469] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:50:44,160] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:44,501] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 392 due to node 1 being disconnected (elapsed time since creation: 3303ms, elapsed time since send: 3171ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:45,398] INFO [BrokerServer id=5] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-01-16 08:50:45,570] INFO [BrokerServer id=5] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2026-01-16 08:50:45,595] INFO [BrokerServer id=5] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-01-16 08:50:45,697] INFO [BrokerServer id=5] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2026-01-16 08:50:45,653] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:45,836] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:50:46,353] INFO [BrokerServer id=5] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2026-01-16 08:50:46,460] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[2026-01-16 08:50:46,467] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser)
[2026-01-16 08:50:46,500] INFO Kafka startTimeMs: 1768553446393 (org.apache.kafka.common.utils.AppInfoParser)
[2026-01-16 08:50:46,468] INFO [RaftManager id=5] Completed transition to Unattached(epoch=555, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=551, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2292, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:46,903] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:50:47,023] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:50:47,829] INFO [RaftManager id=5] Completed transition to Unattached(epoch=557, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=555, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:48,604] INFO [KafkaRaftServer nodeId=5] Kafka Server started (kafka.server.KafkaRaftServer)
[2026-01-16 08:50:49,369] INFO [RaftManager id=5] Completed transition to Unattached(epoch=558, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=557, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:51,799] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=559, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2292, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=558, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:50:52,338] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:51:02,011] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, _schemas-0, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:51:16,975] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 13 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,265] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,328] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,334] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,337] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 9 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,342] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,362] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,363] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,367] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 21 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,381] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,382] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 17 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,384] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,393] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,395] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,404] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 26 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,405] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,405] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,496] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,504] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 38 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,511] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,516] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 1 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,520] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,529] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,536] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,537] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,548] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,558] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 45 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,558] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,559] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 12 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,559] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,559] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 41 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,559] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,559] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 24 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,562] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,564] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 20 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,570] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,571] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 49 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,571] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,571] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,572] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,572] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 29 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,573] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,573] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 25 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,574] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,575] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 8 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,577] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,586] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 37 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,587] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,588] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,588] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,594] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 33 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,595] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,596] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 15 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,601] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,602] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 48 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,610] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,611] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 11 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,621] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,623] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 44 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,628] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,629] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,629] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,630] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,632] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,633] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 32 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,634] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,636] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,642] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,643] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,643] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,647] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,648] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,650] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 3 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,652] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,653] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,657] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,657] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 47 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,658] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,659] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,660] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,672] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 43 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,675] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,678] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,680] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,681] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,682] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,684] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,686] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,685] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-13 in 400 milliseconds for epoch 2, of which 94 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,688] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 351 milliseconds for epoch 3, of which 351 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,687] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 31 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,689] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,691] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-9 in 332 milliseconds for epoch 5, of which 331 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,691] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,691] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,692] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 39 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,692] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,692] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-42 in 325 milliseconds for epoch 4, of which 324 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,694] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-21 in 312 milliseconds for epoch 3, of which 311 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,693] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,695] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,695] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 35 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,695] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-17 in 302 milliseconds for epoch 5, of which 302 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,698] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-30 in 293 milliseconds for epoch 4, of which 293 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,696] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,700] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 2 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:17,699] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-26 in 294 milliseconds for epoch 5, of which 294 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,700] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,713] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-5 in 209 milliseconds for epoch 4, of which 209 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,725] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-38 in 209 milliseconds for epoch 3, of which 209 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,727] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-1 in 206 milliseconds for epoch 5, of which 205 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,728] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 192 milliseconds for epoch 2, of which 192 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,732] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 174 milliseconds for epoch 2, of which 172 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,737] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-45 in 178 milliseconds for epoch 5, of which 178 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,747] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-12 in 188 milliseconds for epoch 3, of which 187 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,750] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-41 in 191 milliseconds for epoch 2, of which 190 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,752] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-24 in 189 milliseconds for epoch 3, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,755] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-20 in 185 milliseconds for epoch 3, of which 184 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,760] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-49 in 189 milliseconds for epoch 2, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:17,760] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-0 in 188 milliseconds for epoch 2, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:21,967] INFO Loaded member MemberMetadata(memberId=sr-1-6a020778-7b37-403a-bbc3-6c4e58ef51d0, groupInstanceId=None, clientId=sr-1, clientHost=/172.24.0.19, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(v0)) in group schema-registry with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2026-01-16 08:51:24,104] INFO [GroupCoordinator 5]: Loading group metadata for schema-registry with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:26,860] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-29 in 9274 milliseconds for epoch 3, of which 187 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,164] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-25 in 9589 milliseconds for epoch 2, of which 9523 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,196] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-8 in 9600 milliseconds for epoch 3, of which 9599 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,226] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-37 in 9638 milliseconds for epoch 5, of which 9637 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,283] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 9689 milliseconds for epoch 2, of which 9688 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,317] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-33 in 9721 milliseconds for epoch 3, of which 9720 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,351] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-15 in 9749 milliseconds for epoch 3, of which 9748 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,363] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-48 in 9752 milliseconds for epoch 3, of which 9752 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,366] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-11 in 9744 milliseconds for epoch 2, of which 9744 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,369] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-44 in 9740 milliseconds for epoch 2, of which 9739 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,371] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-23 in 9740 milliseconds for epoch 4, of which 9740 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,373] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-19 in 9740 milliseconds for epoch 4, of which 9739 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,378] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-32 in 9742 milliseconds for epoch 2, of which 9741 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,387] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 9745 milliseconds for epoch 5, of which 9745 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,388] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-7 in 9741 milliseconds for epoch 4, of which 9741 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,389] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 9739 milliseconds for epoch 3, of which 9739 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,393] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-3 in 9740 milliseconds for epoch 3, of which 9737 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,394] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-36 in 9737 milliseconds for epoch 2, of which 9736 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,401] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-47 in 9742 milliseconds for epoch 2, of which 9739 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,405] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-14 in 9745 milliseconds for epoch 4, of which 9744 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,411] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-43 in 9733 milliseconds for epoch 3, of which 9732 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,413] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 9732 milliseconds for epoch 3, of which 9731 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,422] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 9738 milliseconds for epoch 2, of which 9734 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,427] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-18 in 9740 milliseconds for epoch 2, of which 9740 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,436] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-31 in 9747 milliseconds for epoch 3, of which 9747 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,437] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-27 in 9745 milliseconds for epoch 2, of which 9745 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,443] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-39 in 9750 milliseconds for epoch 5, of which 9750 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,444] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-6 in 9749 milliseconds for epoch 2, of which 9749 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,446] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-35 in 9747 milliseconds for epoch 5, of which 9747 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,462] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-2 in 9746 milliseconds for epoch 3, of which 9746 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2026-01-16 08:51:27,845] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:51:28,807] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group schema-registry in Stable state. Created a new member id sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:30,198] INFO [Partition __consumer_offsets-46 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,274] INFO [Partition __consumer_offsets-9 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,277] INFO [Partition __consumer_offsets-42 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,294] INFO [Partition __consumer_offsets-21 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,296] INFO [Partition __consumer_offsets-17 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,309] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, _schemas-0, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:51:30,311] INFO [Partition __consumer_offsets-30 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,341] INFO [Partition __consumer_offsets-26 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,343] INFO [Partition __consumer_offsets-5 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,344] INFO [Partition __consumer_offsets-38 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,353] INFO [Partition __consumer_offsets-1 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,358] INFO [Partition __consumer_offsets-34 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,358] INFO [Partition __consumer_offsets-16 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,422] INFO [Partition _schemas-0 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,439] INFO [Partition __consumer_offsets-45 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,471] INFO [Partition __consumer_offsets-12 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,472] INFO [Partition __consumer_offsets-41 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,473] INFO [Partition __consumer_offsets-24 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,473] INFO [Partition __consumer_offsets-20 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,479] INFO [Partition __consumer_offsets-49 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,482] INFO [Partition __consumer_offsets-0 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,489] INFO [Partition __consumer_offsets-29 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,494] INFO [Partition __consumer_offsets-25 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,496] INFO [Partition __consumer_offsets-8 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,498] INFO [Partition __consumer_offsets-37 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,505] INFO [Partition __consumer_offsets-4 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,506] INFO [Partition __consumer_offsets-33 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,506] INFO [Partition __consumer_offsets-15 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,509] INFO [Partition __consumer_offsets-48 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,509] INFO [Partition __consumer_offsets-11 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,510] INFO [Partition __consumer_offsets-44 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,511] INFO [Partition __consumer_offsets-23 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,512] INFO [Partition __consumer_offsets-19 broker=5] ISR updated to 5,6  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,518] INFO [Partition __consumer_offsets-32 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,539] INFO [Partition __consumer_offsets-28 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,539] INFO [Partition __consumer_offsets-7 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,540] INFO [Partition __consumer_offsets-40 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,540] INFO [Partition __consumer_offsets-3 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,541] INFO [Partition __consumer_offsets-36 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,568] INFO [Partition __consumer_offsets-47 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,571] INFO [Partition __consumer_offsets-14 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,583] INFO [Partition __consumer_offsets-43 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,609] INFO [Partition __consumer_offsets-10 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,610] INFO [Partition __consumer_offsets-22 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,611] INFO [Partition __consumer_offsets-18 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,615] INFO [Partition __consumer_offsets-31 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,615] INFO [Partition __consumer_offsets-27 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,616] INFO [Partition __consumer_offsets-39 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,616] INFO [Partition __consumer_offsets-6 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,616] INFO [Partition __consumer_offsets-35 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:30,619] INFO [Partition __consumer_offsets-2 broker=5] ISR updated to 5,4  and version updated to 9 (kafka.cluster.Partition)
[2026-01-16 08:51:31,189] INFO [GroupCoordinator 5]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: Adding new member sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb with group instance id None; client reason: rebalance failed due to MemberIdRequiredException) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:31,946] INFO [Partition __consumer_offsets-13 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,291] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-13) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:51:32,453] INFO [Partition __consumer_offsets-46 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,461] INFO [Partition __consumer_offsets-9 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,463] INFO [Partition __consumer_offsets-42 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,474] INFO [Partition __consumer_offsets-21 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,475] INFO [Partition __consumer_offsets-17 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,477] INFO [Partition __consumer_offsets-30 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,480] INFO [Partition __consumer_offsets-26 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,483] INFO [Partition __consumer_offsets-5 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,484] INFO [Partition __consumer_offsets-38 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,486] INFO [Partition __consumer_offsets-1 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,487] INFO [Partition __consumer_offsets-34 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,491] INFO [Partition __consumer_offsets-16 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,496] INFO [Partition __consumer_offsets-45 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,502] INFO [Partition __consumer_offsets-12 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,511] INFO [Partition __consumer_offsets-41 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,539] INFO [Partition __consumer_offsets-48 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,541] INFO [Partition __consumer_offsets-11 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:32,674] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-48, __consumer_offsets-45, __consumer_offsets-46, __consumer_offsets-14, __consumer_offsets-11, __consumer_offsets-43, __consumer_offsets-12, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-42, __consumer_offsets-10, __consumer_offsets-21, __consumer_offsets-22, __consumer_offsets-17, __consumer_offsets-18, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:51:33,189] INFO [Partition _schemas-0 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,303] INFO [Partition __consumer_offsets-24 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,778] INFO [Partition __consumer_offsets-20 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,780] INFO [Partition __consumer_offsets-49 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,808] INFO [Partition __consumer_offsets-0 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,825] INFO [Partition __consumer_offsets-29 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,839] INFO [Partition __consumer_offsets-25 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,848] INFO [Partition __consumer_offsets-8 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,857] INFO [Partition __consumer_offsets-37 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,868] INFO [Partition __consumer_offsets-4 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,883] INFO [Partition __consumer_offsets-33 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,889] INFO [Partition __consumer_offsets-15 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,902] INFO [Partition __consumer_offsets-44 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,916] INFO [Partition __consumer_offsets-23 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,930] INFO [Partition __consumer_offsets-19 broker=5] ISR updated to 5,6,4  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,953] INFO [Partition __consumer_offsets-32 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,962] INFO [Partition __consumer_offsets-28 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,968] INFO [Partition __consumer_offsets-7 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,987] INFO [Partition __consumer_offsets-40 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:33,999] INFO [Partition __consumer_offsets-3 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:34,002] INFO [Partition __consumer_offsets-36 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:34,012] INFO [Partition __consumer_offsets-6 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:34,077] INFO [Partition __consumer_offsets-35 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:34,091] INFO [Partition __consumer_offsets-2 broker=5] ISR updated to 5,4,6  and version updated to 10 (kafka.cluster.Partition)
[2026-01-16 08:51:35,873] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-15, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, _schemas-0, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-39, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:51:37,742] INFO [GroupCoordinator 5]: Member sr-1-6a020778-7b37-403a-bbc3-6c4e58ef51d0 in group schema-registry has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:39,511] INFO [GroupCoordinator 5]: Stabilized group schema-registry generation 2 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:51:42,730] INFO [GroupCoordinator 5]: Assignment received from leader sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb for group schema-registry for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:53:38,755] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:08,384] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 85 due to node 2 being disconnected (elapsed time since creation: 34039ms, elapsed time since send: 34038ms, throttle time: 0ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:08,728] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:08,742] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:13,690] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:13,990] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:14,497] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 496 due to node 1 being disconnected (elapsed time since creation: 2249ms, elapsed time since send: 2006ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:15,819] INFO [Partition __consumer_offsets-29 broker=5] Shrinking ISR from 5,6,4 to 5. Leader: (highWatermark: 1, endOffset: 2). Out of sync replicas: (brokerId: 6, endOffset: 1, lastCaughtUpTimeMs: 1768553509020) (brokerId: 4, endOffset: 1, lastCaughtUpTimeMs: 1768553508960). (kafka.cluster.Partition)
[2026-01-16 08:54:15,881] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:15,899] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:18,281] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:18,524] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 497 due to node 2 being disconnected (elapsed time since creation: 3920ms, elapsed time since send: 2312ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:28,672] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:28,829] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:33,687] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:34,275] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:34,369] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 501 due to node 1 being disconnected (elapsed time since creation: 3830ms, elapsed time since send: 2007ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:34,572] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:34,627] INFO [GroupCoordinator 5]: Assignment received from leader sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb for group schema-registry for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:54:34,629] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:36,635] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:37,347] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:38,169] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:38,311] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:38,411] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:41,443] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:41,568] INFO [RaftManager id=5] Completed transition to Unattached(epoch=575, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=559, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:54:41,618] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:41,572] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:44,127] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:44,137] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:44,128] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=576, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=575, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:54:45,644] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:45,656] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:47,866] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:47,889] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:47,919] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:48,753] INFO [RaftManager id=5] Completed transition to Unattached(epoch=580, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=576, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:54:49,040] INFO [GroupCoordinator 5]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 2 (__consumer_offsets-29) (reason: Error REBALANCE_IN_PROGRESS when storing group assignment during SyncGroup (member: sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb)) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:54:49,557] INFO [GroupCoordinator 5]: Stabilized group schema-registry generation 3 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:54:50,662] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:52,816] INFO [GroupCoordinator 5]: Assignment received from leader sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb for group schema-registry for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:54:53,146] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:53,884] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:53,922] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:53,964] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=582, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=580, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:54:54,212] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:54,238] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:54,295] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:54,379] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:54,384] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:55,873] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:56,095] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:56,112] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:56,209] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=585, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=582, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:54:57,461] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:54:58,067] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:54:58,729] INFO [RaftManager id=5] Completed transition to Unattached(epoch=586, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=585, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:54:59,404] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:54:59,726] INFO [GroupCoordinator 5]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 3 (__consumer_offsets-29) (reason: Error REBALANCE_IN_PROGRESS when storing group assignment during SyncGroup (member: sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb)) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:55:02,535] INFO [GroupCoordinator 5]: Stabilized group schema-registry generation 4 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:55:03,401] INFO [GroupCoordinator 5]: Assignment received from leader sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb for group schema-registry for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:55:04,235] INFO [RaftManager id=5] Completed transition to Unattached(epoch=589, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=586, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:06,580] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=590, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=589, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:06,597] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:09,114] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:09,166] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:09,177] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:09,271] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:09,347] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:10,259] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:10,273] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:10,326] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:10,326] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:10,330] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:55:10,367] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:12,251] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:12,390] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 522 due to node 3 being disconnected (elapsed time since creation: 2050ms, elapsed time since send: 2045ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:13,204] INFO [RaftManager id=5] Completed transition to Unattached(epoch=593, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=590, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:13,331] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:14,892] INFO [RaftManager id=5] Completed transition to Unattached(epoch=594, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=593, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:15,895] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=595, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=594, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:15,983] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:17,486] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:17,873] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:19,141] INFO [RaftManager id=5] Completed transition to Unattached(epoch=596, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=595, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:19,965] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:21,046] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=599, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=596, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:21,151] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:21,853] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:22,858] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:23,621] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:23,696] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:24,023] INFO [RaftManager id=5] Completed transition to Unattached(epoch=600, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=599, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:24,145] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:24,249] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:25,147] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:55:25,648] INFO [RaftManager id=5] Completed transition to Unattached(epoch=603, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=600, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:25,963] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=603, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2596, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=603, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:25,992] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:26,039] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:29,553] INFO [Partition __consumer_offsets-29 broker=5] ISR updated to 5  and version updated to 11 (kafka.cluster.Partition)
[2026-01-16 08:55:29,968] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:55:36,406] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:36,620] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:55:37,153] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:37,872] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:55:37,956] INFO [RaftManager id=5] Completed transition to Unattached(epoch=604, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=603, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:55:39,943] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:55:51,326] INFO [GroupCoordinator 5]: Member sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb in group schema-registry has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:55:59,972] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:02,111] INFO [GroupCoordinator 5]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 4 (__consumer_offsets-29) (reason: removing member sr-1-e62db0b3-13b7-4d47-8090-857ecbf5befb on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:03,858] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 543 due to node 2 being disconnected (elapsed time since creation: 5616ms, elapsed time since send: 5528ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:05,586] INFO [GroupCoordinator 5]: Group schema-registry with generation 5 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:05,806] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:56:06,349] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:06,709] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 545 due to node 1 being disconnected (elapsed time since creation: 22436ms, elapsed time since send: 2027ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:06,802] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:06,803] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 544 due to node 3 being disconnected (elapsed time since creation: 25347ms, elapsed time since send: 2027ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:20,665] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:56:21,718] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:21,816] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 552 due to node 3 being disconnected (elapsed time since creation: 5936ms, elapsed time since send: 5936ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:23,131] WARN [GroupCoordinator 5]: Failed to write empty metadata for group schema-registry: The group is rebalancing, so a rejoin is needed. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:23,139] INFO [RaftManager id=5] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:23,444] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 555 due to node 1 being disconnected (elapsed time since creation: 3931ms, elapsed time since send: 3931ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:23,445] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:23,445] INFO [RaftManager id=5] Cancelled in-flight API_VERSIONS request with correlation id 556 due to node 2 being disconnected (elapsed time since creation: 3931ms, elapsed time since send: 3931ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:24,037] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group schema-registry in Empty state. Created a new member id sr-1-fdf07d79-beb7-4769-9925-953baba62875 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:31,824] INFO [GroupCoordinator 5]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 5 (__consumer_offsets-29) (reason: Adding new member sr-1-fdf07d79-beb7-4769-9925-953baba62875 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:36,155] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:56:38,297] INFO [RaftManager id=5] Completed transition to Unattached(epoch=622, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=604, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:56:43,676] INFO [GroupCoordinator 5]: Stabilized group schema-registry generation 6 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:46,201] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:46,944] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 564 due to node 3 being disconnected (elapsed time since creation: 5311ms, elapsed time since send: 4310ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:48,979] INFO [GroupCoordinator 5]: Assignment received from leader sr-1-fdf07d79-beb7-4769-9925-953baba62875 for group schema-registry for generation 6. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:51,627] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:56:51,629] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=628, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=622, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:56:51,658] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:56:51,745] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:56:55,141] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:55,409] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:56:57,697] INFO [GroupCoordinator 5]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 6 (__consumer_offsets-29) (reason: Error REBALANCE_IN_PROGRESS when storing group assignment during SyncGroup (member: sr-1-fdf07d79-beb7-4769-9925-953baba62875)) (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:56:58,471] INFO [RaftManager id=5] Disconnecting from node 2 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:58,487] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 570 due to node 2 being disconnected (elapsed time since creation: 2887ms, elapsed time since send: 2469ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:58,922] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:56:59,019] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:04,754] INFO [GroupCoordinator 5]: Stabilized group schema-registry generation 7 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:57:05,288] INFO [RaftManager id=5] Completed transition to Unattached(epoch=634, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=628, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:06,176] INFO [GroupCoordinator 5]: Assignment received from leader sr-1-fdf07d79-beb7-4769-9925-953baba62875 for group schema-registry for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2026-01-16 08:57:06,541] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:07,035] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:08,206] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:08,260] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 572 due to node 3 being disconnected (elapsed time since creation: 2229ms, elapsed time since send: 2037ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:09,299] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:57:10,845] INFO [RaftManager id=5] Completed transition to Unattached(epoch=638, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=634, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:17,331] INFO [RaftManager id=5] Disconnecting from node 3 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:18,667] INFO [RaftManager id=5] Cancelled in-flight FETCH request with correlation id 576 due to node 3 being disconnected (elapsed time since creation: 5333ms, elapsed time since send: 4261ms, throttle time: 0ms, request timeout: 2000ms) (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:21,784] INFO [RaftManager id=5] Completed transition to Unattached(epoch=645, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=638, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:23,772] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:57:24,131] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:24,162] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=645, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=645, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:24,173] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:28,897] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:29,832] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:32,503] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=647, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=645, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:35,970] INFO [RaftManager id=5] Completed transition to Unattached(epoch=650, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=647, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:36,344] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:36,452] INFO [RaftManager id=5] Completed transition to Unattached(epoch=651, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=650, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:39,009] WARN [BrokerLifecycleManager id=5] Broker 5 sent a heartbeat request but received error REQUEST_TIMED_OUT. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:57:39,584] INFO [RaftManager id=5] Completed transition to Unattached(epoch=652, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=651, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:40,520] INFO [RaftManager id=5] Completed transition to Unattached(epoch=653, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=652, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:42,956] INFO [RaftManager id=5] Completed transition to Unattached(epoch=656, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=653, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:45,111] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=656, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=656, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:45,187] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:46,971] INFO [NodeToControllerChannelManager id=5 name=alter-partition] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:57:47,024] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:47,047] INFO [broker-5-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:57:48,018] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=659, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=656, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2618, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:57:48,203] INFO [Partition __consumer_offsets-29 broker=5] ISR updated to 5,6  and version updated to 12 (kafka.cluster.Partition)
[2026-01-16 08:57:48,681] INFO [Partition __consumer_offsets-29 broker=5] ISR updated to 5,6,4  and version updated to 13 (kafka.cluster.Partition)
[2026-01-16 08:57:49,543] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:57:55,501] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2026-01-16 08:58:24,716] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:58:27,439] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:58:27,448] INFO [RaftManager id=5] Completed transition to Unattached(epoch=660, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=659, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2698, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:58:27,729] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:58:27,926] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=663, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2698, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=660, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:58:40,157] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:58:40,469] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-3:9093 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:58:40,597] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:58:40,733] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=666, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2715, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=663, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2715, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:59:10,224] INFO [RaftManager id=5] Completed transition to Unattached(epoch=668, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from FollowerState(fetchTimeoutMs=2000, epoch=666, leader=kafka-controller-3:9093 (id: 3 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2761, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:59:10,245] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 3 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:59:11,443] INFO [RaftManager id=5] Completed transition to Unattached(epoch=673, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) from Unattached(epoch=668, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:59:13,254] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=674, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2761, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from Unattached(epoch=673, voters=[1, 2, 3], electionTimeoutMs=9223372036854775807) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:59:13,287] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:59:16,567] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:59:19,783] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-2:9093 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2026-01-16 08:59:19,917] INFO [BrokerLifecycleManager id=5] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2026-01-16 08:59:21,935] INFO [NodeToControllerChannelManager id=5 name=heartbeat] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2026-01-16 08:59:22,928] INFO [RaftManager id=5] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=680, leader=kafka-controller-1:9093 (id: 1 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2770, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) from FollowerState(fetchTimeoutMs=2000, epoch=674, leader=kafka-controller-2:9093 (id: 2 rack: null) voters=[1, 2, 3], highWatermark=Optional[LogOffsetMetadata(offset=2770, metadata=Optional.empty)], fetchingSnapshot=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2026-01-16 08:59:23,633] INFO [broker-5-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka-controller-1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
